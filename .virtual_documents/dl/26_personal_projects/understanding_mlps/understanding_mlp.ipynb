








import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt


# Train models to separate the XOR dataset, feel free to skip. 
EPOCHS = 1000
LR = 1
MANUAL_SEED = 0
ACC_SPACING = 100

act_fn_by_name = {
    "tanh": nn.Tanh,
    "relu": nn.ReLU,
    "identity": nn. Identity
}

model_name_to_config = {
    "0_hidden_layer" : [()], 
    "1_hidden_layer_1_unit_identity" : [(1,), "identity"],
    "1_hidden_layer_2_unit_identity" : [(2,), "identity"], 
    "1_hidden_layer_3_unit_identity" : [(3,), "identity"], 
    "1_hidden_layer_10_unit_identity" : [(10,), "identity"], 
    "1_hidden_layer_1_unit_relu" : [(1,), "relu"], 
    "1_hidden_layer_1_unit_tanh" : [(1,), "tanh"], 
    "1_hidden_layer_2_unit_relu" : [(2,), "relu"], 
    "1_hidden_layer_2_unit_tanh" : [(2,), "tanh"], 
    "10_hidden_layer_3_unit_identity" : [(3,)*10, "identity"], 
}

class MLP(nn.Module):
    
    def __init__(self, hidden_units, act_fn = 'tanh'):
        super().__init__()
        hidden_layers = []
        for num_hidden in hidden_units:
            hidden_layers.append(nn.LazyLinear(num_hidden))
            hidden_layers.append(act_fn_by_name[act_fn]())
        self.hidden_layers = nn.Sequential(*hidden_layers)
        self.linear = nn.LazyLinear(1)

    def forward(self, x):
        x = self.hidden_layers(x)
        x = self.linear(x)
        return x

device = torch.device("mps") if torch.mps.is_available() else torch.device("cpu")
print("Device", device)
torch.mps.manual_seed(42)

# XOR
xs = torch.tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype = torch.float32).to(device)
ys = torch.tensor([1, 0, 0, 1], dtype = torch.float32).to(device)
loss_module = nn.BCEWithLogitsLoss()

# Train models
model_name_to_results = {}
for model_name in model_name_to_config:
    torch.manual_seed(1)
    model = MLP(*model_name_to_config[model_name]).to(device)
    optimizer = torch.optim.SGD(model.parameters(), lr = LR)
    losses = []
    accs = []
    state_dicts = []
    for epoch in range(EPOCHS+1):
        preds = model(xs).flatten()
        if epoch % 100 == 0:
            acc = (((torch.sigmoid(preds) > 0.5) == ys).sum()/ys.shape[0])
            acc = int(acc.detach().numpy()*100)
            accs.append(acc)
        loss = loss_module(preds, ys)
        losses.append(loss.item())
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        state_dicts.append(model.state_dict())
    model_name_to_results[model_name] = {
        "weights" : state_dicts,
        "accuracies" : accs, 
        "losses" : losses
    }

# Plot results
fig, axs = plt.subplots(ncols = 2, figsize = (20,7))
for model_name in model_name_to_results:
    accs = model_name_to_results[model_name]["accuracies"]
    axs[0].plot(np.linspace(0, EPOCHS + 1, len(accs)), accs, label = model_name)
    axs[1].plot(model_name_to_results[model_name]["losses"], label = model_name)
for ax in axs:
    ax.legend()
axs[0].set_ylim([-5,105])
axs[0].set_title("Accuracy by Epoch")
axs[1].set_title("Loss by Epoch")
axs[0].set_ylabel("Accuracy (%)")
axs[1].set_ylabel("Loss")
fig.tight_layout();

















def get_decision_boundary(model):
    """ Function to return the x-y coodinates of the decision boundary given a model.
        This assumes the second to last hidden layer is a 2 hidden unit layer with a bias term
        and sigmoid activation on the last layer."""
    a = model.layers[-1].get_weights()[0][0][0]
    b = model.layers[-1].get_weights()[0][1][0]
    c = model.layers[-1].get_weights()[1][0]
    decision_x = np.linspace(-1,1,100)
    decision_y = (scipy.special.logit(.5)-c-a*decision_x)/b
    return decision_x, decision_y


import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
from keras import backend as K

def animate_model(model, n_frames=100):
    """ Function to animate a model's first n_frames epochs of training. """
    
    # Define necessary lines to plot a grid-- this will represent the vanilla "input space".
    grids = [np.column_stack((np.linspace(-1,1, 100), k*np.ones(100)/10.)) for k in range(-10,11)] +\
                [np.column_stack((k*np.ones(100)/10.,np.linspace(-1,1, 100))) for k in range(-10,11) ]

    # Define functions for the output of the 2-hidden unit layer. 
    # We assume this is the second to last layer
    f = K.function(inputs = model.inputs, outputs = model.layers[-1].output)
    
    decision_x, decision_y = get_decision_line(model)

    # Plot the original space's deformation by the neural network and use it as the init()
    fig, ax = plt.subplots()

    orig_vals = f(inputs=[df[['x','y']].values])
    line, = ax.plot(decision_x,decision_y,color='black')
    lineb, = ax.plot(orig_vals[indb,0], orig_vals[indb,1], marker='.', color='b')
    liner, = ax.plot(orig_vals[indr,0], orig_vals[indr,1], marker='.', color='r')
    grid_lines = []

    for grid in grids:
        vals = np.array(grid)
        l, = ax.plot(vals[:,0],vals[:,1], color='grey', alpha=.5)
        grid_lines.append(l)

    all_lines = tuple([line, lineb, liner, *grid_lines])

    def animate(i):
        model.fit(df[['x','y']].values, df[['label']].values, epochs=1, batch_size=32, verbose=0)
        line.set_data(*get_decision_line(model))
        vals = f(inputs = [df[['x','y']].values])
        lineb.set_data(vals[indb,0], vals[indb,1])
        liner.set_data(vals[indr,0], vals[indr,1])

        for k in range(len(grid_lines)):
            ln = grid_lines[k]
            grid = grids[k]
            vals = f(inputs = [np.array(grid)])
            ln.set_data(vals[:,0],vals[:,1])

        return all_lines

    def init():
        line.set_ydata(np.ma.array(decision_x, mask=True))
        lineb.set_data(orig_vals[indb,0],orig_vals[indb,1])
        liner.set_data(orig_vals[indr,0],orig_vals[indr,1])
        for k in range(len(grid_lines)):
            ln = grid_lines[k]
            grid = grids[k]
            vals = f(inputs = [np.array(grid)])
            ln.set_data(vals[:,0],vals[:,1])
        return all_lines

    return animation.FuncAnimation(fig, animate, np.arange(1, n_frames), init_func=init,
                                  interval=100, blit=True)


import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

# Create a 2D grid of points
x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
X, Y = np.meshgrid(x, y)

# Function to apply tanh to each point in the grid
def transform(X, Y, t):
    # Here, we apply tanh elementwise to the grid, modulating over time `t`
    return np.tanh(X * np.cos(t) + Y * np.sin(t))

# Set up the figure and axis
fig, ax = plt.subplots()
contour = ax.contourf(X, Y, transform(X, Y, 0), levels=20, cmap='viridis')
ax.set_title('Transformation of 2D Grid by tanh')
ax.set_xlabel('X')
ax.set_ylabel('Y')

# Update function for the animation
def update(t):
    ax.clear()  # Clear the axis
    ax.set_title(f'Transformation of 2D Grid by tanh (t = {t:.2f})')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    
    Z = transform(X, Y, t)  # Apply tanh transformation
    ax.contourf(X, Y, Z, levels=20, cmap='viridis')  # Redraw contour plot
    return contour.collections

# Set up the animation
ani = animation.FuncAnimation(fig, update, frames=np.linspace(0, 10, 100), interval=100)

plt.show()


fig, ax = plt.subplots()
t = np.linspace(0, 3, 40)
g = -9.81
v0 = 12
z = g * t**2 / 2 + v0 * t

v02 = 5
z2 = g * t**2 / 2 + v02 * t

scat = ax.scatter(t[0], z[0], c="b", s=5, label=f'v0 = {v0} m/s')
line2 = ax.plot(t[0], z2[0], label=f'v0 = {v02} m/s')[0]
ax.set(xlim=[0, 3], ylim=[-4, 10], xlabel='Time [s]', ylabel='Z [m]')
ax.legend()


def update(frame):
    # for each frame, update the data stored on each artist.
    x = t[:frame]
    y = z[:frame]
    # update the scatter plot:
    data = np.stack([x, y]).T
    scat.set_offsets(data)
    # update the line plot:
    line2.set_xdata(t[:frame])
    line2.set_ydata(z2[:frame])
    return (scat, line2)


ani = animation.FuncAnimation(fig=fig, func=update, frames=40, interval=30)
plt.show()


# %matplotlib widget
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

fig, ax = plt.subplots()

# Create initial grid lines
x = np.linspace(-5, 5, 11)
y = np.linspace(-5, 5, 11)
grid_lines = []
for i in range(len(x)):
    grid_lines.append(ax.plot([x[i], x[i]], [-5, 5], color='gray', linestyle='--')[0])
    grid_lines.append(ax.plot([-5, 5], [y[i], y[i]], color='gray', linestyle='--')[0])

# Animation function
def animate(i):
    angle = np.radians(i)
    for line in grid_lines:
        xdata, ydata = line.get_data()
        xdata_new = xdata * np.cos(angle) - ydata * np.sin(angle)
        ydata_new = xdata * np.sin(angle) + ydata * np.cos(angle)
        line.set_data(xdata_new, ydata_new)
    return grid_lines

# Create animation
ani = animation.FuncAnimation(fig, animate, frames=360, interval=20, blit=True)
plt.show()









