{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b607b5ba-ed4f-46ba-b0cd-f571b1b947d5",
   "metadata": {},
   "source": [
    "# Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c0ae781-4c36-46c0-8369-d780b20aa6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRJRDownloaded 160 sites in 7.431119749999198 seconds\n"
     ]
    }
   ],
   "source": [
    "# Synchronous\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "def download_site(url):\n",
    "    requests.get(url)\n",
    "    indicator = \"J\" if \"jython\" in url else \"R\"\n",
    "    print(indicator, sep='', end='', flush=True)\n",
    "\n",
    "def download_site_verbose(url):\n",
    "    with requests.Session() as session:\n",
    "        response = session.get(url)\n",
    "        indicator = \"J\" if \"jython\" in url else \"R\"\n",
    "        print(indicator, sep='', end='', flush=True)\n",
    "\n",
    "sites = [\n",
    "        \"https://www.jython.org\",\n",
    "        \"http://olympus.realpython.org/dice\",\n",
    "    ] * 80\n",
    "\n",
    "start = time.perf_counter()\n",
    "for url in sites:\n",
    "    download_site(url)\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Downloaded {len(sites)} sites in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37602932-3ad9-4ffe-933c-cd178b141314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRJJJJJRRRJJRRJRRRJJJRRJJRRRJJJRRJJRJJJRRJRRRJJJRJRRJJRRJJRRJRJJRRRJRJJRRJJRJJRRJRRJJRRJJJRRJJRRJJRRJJRJRRJJRRJRRJJRRRJJJJJRRRJRJRJRRRJJJJRRJRJRJRJRJRJJRRRJJRJRDownloaded 160 sites in 1.4381094589989516 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(download_site, sites)\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Downloaded {len(sites)} sites in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24912a2a-2bae-487e-9533-809a9c43355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRJJJJJRRRJRRJJJRJRRJRJJRRJJRRJRJJRRJRJRRJJRJRRJJRJJRJRRJJRRRJJJRRRRJJJRRJJRRJJRJRRJJRRRJJJRRJJRJJRRJJJRRRJRRJJRJRRJJRJJRRJRJRRJRJJJRJRRRJJRJRJRJRJJJRRRJRJJRJRRDownloaded 160 sites in 1.4759474589955062 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    executor.map(download_site_verbose, sites)\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Downloaded {len(sites)} sites in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "132a0b6f-d0ee-4884-bf74-aa66da625bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with balance of 100\n",
      "deposit thread updating...\n",
      "withdrawal thread updating...\n",
      "deposit thread finishing...\n",
      "withdrawal thread finishing...\n",
      "ending balance of 0\n"
     ]
    }
   ],
   "source": [
    "# Locking, submit\n",
    "class Account:\n",
    "    def __init__(self):\n",
    "        self.balance = 100 # shared data\n",
    "        self.lock = threading.Lock()\n",
    "    def update(self, transaction, amount):\n",
    "        print(f'{transaction} thread updating...')\n",
    "        with self.lock:\n",
    "            local_copy = self.balance\n",
    "            local_copy += amount\n",
    "            time.sleep(1)\n",
    "            self.balance = local_copy\n",
    "        print(f'{transaction} thread finishing...')\n",
    "\n",
    "account = Account()\n",
    "print(f'starting with balance of {account.balance}')\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as ex:\n",
    "    for transaction, amount in [('deposit', 50), ('withdrawal', -150)]:\n",
    "        ex.submit(account.update, transaction, amount)\n",
    "print(f'ending balance of {account.balance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e422d92e-e83d-4814-b412-ef8ef48d1683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Event\n",
    "event = threading.Event()\n",
    "print(event.is_set())\n",
    "event.set()\n",
    "print(event.is_set())\n",
    "event.clear()\n",
    "print(event.is_set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d6225f7-62e7-47e5-a4ff-6f23b0222847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "s = threading.Semaphore(value=10)\n",
    "s.acquire()\n",
    "print(s._value)\n",
    "s.release()\n",
    "print(s._value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "16173f69-1621-4226-babc-f30194d07895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome visitor #0\n",
      "[monitor] semaphore=9\n",
      "welcome visitor #1\n",
      "welcome visitor #2\n",
      "[monitor] semaphore=1\n",
      "welcome visitor #3\n",
      "welcome visitor #4\n",
      "welcome visitor #5\n",
      "[monitor] semaphore=4\n",
      "welcome visitor #6\n",
      "welcome visitor #7\n",
      "welcome visitor #8\n",
      "[monitor] semaphore=1\n",
      "welcome visitor #9\n",
      "welcome visitor #10\n",
      "[monitor] reached max users!\n",
      "[monitor] kicking a user out...\n",
      "[monitor] semaphore=0\n",
      "welcome visitor #11\n",
      "[monitor] semaphore=1\n",
      "[monitor] reached max users!\n",
      "[monitor] kicking a user out...\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def welcome(semaphore, stop):\n",
    "    visitor_number = 0\n",
    "    while True and not stop.is_set():\n",
    "        print(f'welcome visitor #{visitor_number}')\n",
    "        semaphore.acquire() # reduces value, is blocked when the counter is zero until release is called\n",
    "        visitor_number += 1\n",
    "        time.sleep(random.random())\n",
    "    \n",
    "def monitor(semaphore, stop):\n",
    "    while True and not stop.is_set():\n",
    "        print(f'[monitor] semaphore={semaphore._value}')\n",
    "        time.sleep(3)\n",
    "        if semaphore._value == 0:\n",
    "            print('[monitor] reached max users!')\n",
    "            print('[monitor] kicking a user out...')\n",
    "            semaphore.release() # increases value\n",
    "            time.sleep(0.05)\n",
    "\n",
    "stop = threading.Event()\n",
    "semaphore = threading.Semaphore(value=10)\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    executor.submit(welcome, semaphore, stop)\n",
    "    executor.submit(monitor, semaphore, stop)\n",
    "    time.sleep(7)\n",
    "    stop.set()\n",
    "\n",
    "# Counting is atomic. This means that there is a guarantee that the operating system will not swap out the thread in the middle of incrementing or decrementing the counter.\n",
    "# If a thread calls .acquire() when the counter is zero, that thread will block until a different thread calls .release() and increments the counter to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d157b7-683c-40cd-bf1e-9fc2019769e2",
   "metadata": {},
   "source": [
    "# MultiProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "031c117c-82e3-4b2b-bb6f-a08d2b1b5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "start = time.perf_counter()\n",
    "with multiprocessing.Pool() as pool:\n",
    "    pool.map(download_site, sites)\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Downloaded {len(sites)} sites in {duration} seconds\")\n",
    "\n",
    "# multiprocessing.Pool(initializer=set_global_session)\n",
    "# If initializer is not None then each worker process will call initializer(*initargs) when it starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04ef6b89-e03e-4e88-b95a-73e1167f37a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 4.790480667004886 seconds\n"
     ]
    }
   ],
   "source": [
    "# Synchronous\n",
    "import time\n",
    "\n",
    "def calculate(limit):\n",
    "    return sum(i * i for i in range(limit))\n",
    "\n",
    "numbers = [5_000_000 + x for x in range(20)]\n",
    "start = time.perf_counter()\n",
    "for number in numbers:\n",
    "    calculate(number)\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Duration {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2948c67-295e-48fd-972d-9cd8b9c0fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concurrent\n",
    "print(multiprocessing.cpu_count())\n",
    "start = time.perf_counter()\n",
    "with multiprocessing.Pool() as pool:\n",
    "    pool.map(calculate, numbers)\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Duration {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06154361-cc4f-46a5-8502-8878fa04df8f",
   "metadata": {},
   "source": [
    "# Asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90823d-5b41-4748-9d04-b4452aa20a53",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10700aba-2190-46c8-851c-161646252706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80f14ab6-5b85-4e1e-9aa0-752bd345a946",
   "metadata": {},
   "source": [
    "## aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd67ff6c-6eca-4f39-9fd6-6bf37aad07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import aiohttp\n",
    "\n",
    "async def download_site(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        indicator = \"J\" if \"jython\" in url else \"R\"\n",
    "        print(indicator, sep='', end='', flush=True)\n",
    "\n",
    "async def download_all_sites(sites):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in sites:\n",
    "            task = asyncio.ensure_future(download_site(session, url))\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "print(\"Starting downloads\")\n",
    "start = time.perf_counter()\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(download_all_sites(sites))\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"\\nDownloaded {len(sites)} sites in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf7e34-3cf9-4d4a-9fca-b13bf0f4b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "from typing import IO\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(name)s: %(message)s\",\n",
    "    level=logging.DEBUG,\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    stream=sys.stderr,\n",
    ")\n",
    "logger = logging.getLogger(\"areq\")\n",
    "logging.getLogger(\"chardet.charsetprober\").disabled = True\n",
    "\n",
    "HREF_RE = re.compile(r'href=\"(.*?)\"')\n",
    "\n",
    "async def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n",
    "    \"\"\"GET request wrapper to fetch page HTML.\n",
    "\n",
    "    kwargs are passed to `session.request()`.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = await session.request(method=\"GET\", url=url, **kwargs)\n",
    "    resp.raise_for_status()\n",
    "    logger.info(\"Got response [%s] for URL: %s\", resp.status, url)\n",
    "    html = await resp.text()\n",
    "    return html\n",
    "\n",
    "async def parse(url: str, session: ClientSession, **kwargs) -> set:\n",
    "    \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n",
    "    found = set()\n",
    "    try:\n",
    "        html = await fetch_html(url=url, session=session, **kwargs)\n",
    "    except (\n",
    "        aiohttp.ClientError,\n",
    "        aiohttp.http_exceptions.HttpProcessingError,\n",
    "    ) as e:\n",
    "        logger.error(\n",
    "            \"aiohttp exception for %s [%s]: %s\",\n",
    "            url,\n",
    "            getattr(e, \"status\", None),\n",
    "            getattr(e, \"message\", None),\n",
    "        )\n",
    "        return found\n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Non-aiohttp exception occured:  %s\", getattr(e, \"__dict__\", {})\n",
    "        )\n",
    "        return found\n",
    "    else:\n",
    "        for link in HREF_RE.findall(html):\n",
    "            try:\n",
    "                abslink = urllib.parse.urljoin(url, link)\n",
    "            except (urllib.error.URLError, ValueError):\n",
    "                logger.exception(\"Error parsing URL: %s\", link)\n",
    "                pass\n",
    "            else:\n",
    "                found.add(abslink)\n",
    "        logger.info(\"Found %d links for %s\", len(found), url)\n",
    "        return found\n",
    "\n",
    "async def write_one(file: IO, url: str, **kwargs) -> None:\n",
    "    \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n",
    "    res = await parse(url=url, **kwargs)\n",
    "    if not res:\n",
    "        return None\n",
    "    async with aiofiles.open(file, \"a\") as f:\n",
    "        for p in res:\n",
    "            await f.write(f\"{url}\\t{p}\\n\")\n",
    "        logger.info(\"Wrote results for source URL: %s\", url)\n",
    "\n",
    "async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n",
    "    \"\"\"Crawl & write concurrently to `file` for multiple `urls`.\"\"\"\n",
    "    async with ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            tasks.append(\n",
    "                write_one(file=file, url=url, session=session, **kwargs)\n",
    "            )\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pathlib\n",
    "    import sys\n",
    "\n",
    "    assert sys.version_info >= (3, 7), \"Script requires Python 3.7+.\"\n",
    "    here = pathlib.Path(__file__).parent\n",
    "\n",
    "    with open(here.joinpath(\"urls.txt\")) as infile:\n",
    "        urls = set(map(str.strip, infile))\n",
    "\n",
    "    outpath = here.joinpath(\"foundurls.txt\")\n",
    "    with open(outpath, \"w\") as outfile:\n",
    "        outfile.write(\"source_url\\tparsed_url\\n\")\n",
    "\n",
    "    asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a09179-f6d0-434a-849c-3d5eeefc2097",
   "metadata": {},
   "source": [
    "## aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2896a07-1c23-4e56-a7f5-03b3f862ea8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
