{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efbd4a3-973f-4ed5-b5bd-9533d5779e33",
   "metadata": {},
   "source": [
    "# Code adapted from\n",
    "- http://d2l.ai/chapter_natural-language-processing-pretraining/bert.html\n",
    "- https://github.com/rasbt/LLMs-from-scratch\n",
    "- https://huggingface.co/learn/nlp-course/en/chapter6/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b3929-c630-4e1d-a208-f4bdab0341dd",
   "metadata": {},
   "source": [
    "## Input Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07f72a3-5f94-43a3-9a11-4e90d8460a16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ed5f5c-b8c1-4175-89f6-96c06153574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14c4cb4-5cf4-4085-a14d-beef91d778b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"This is the Hugging Face Course.\",\n",
    "    \"This chapter is about tokenization.\",\n",
    "    \"This section shows several tokenizer algorithms.\",\n",
    "    \"Hopefully, you will be able to understand how they are trained and generate tokens.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea1c3bc-603a-47c5-a7dd-7579f99f0d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hopefully', (0, 9)),\n",
       " (',', (9, 10)),\n",
       " ('Ġyou', (10, 14)),\n",
       " ('Ġwill', (14, 19)),\n",
       " ('Ġbe', (19, 22)),\n",
       " ('Ġable', (22, 27)),\n",
       " ('Ġto', (27, 30)),\n",
       " ('Ġunderstand', (30, 41)),\n",
       " ('Ġhow', (41, 45)),\n",
       " ('Ġthey', (45, 50)),\n",
       " ('Ġare', (50, 54)),\n",
       " ('Ġtrained', (54, 62)),\n",
       " ('Ġand', (62, 66)),\n",
       " ('Ġgenerate', (66, 75)),\n",
       " ('Ġtokens', (75, 82)),\n",
       " ('.', (82, 83))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(corpus[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c1b8f5-3368-45c5-a452-909d6bd517bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.': 4, 'This': 3, 'Ġis': 2, 'Ġthe': 1, 'ĠHugging': 1, 'ĠFace': 1, 'ĠCourse': 1, 'Ġchapter': 1, 'Ġabout': 1, 'Ġtokenization': 1, 'Ġsection': 1, 'Ġshows': 1, 'Ġseveral': 1, 'Ġtokenizer': 1, 'Ġalgorithms': 1, 'Hopefully': 1, ',': 1, 'Ġyou': 1, 'Ġwill': 1, 'Ġbe': 1, 'Ġable': 1, 'Ġto': 1, 'Ġunderstand': 1, 'Ġhow': 1, 'Ġthey': 1, 'Ġare': 1, 'Ġtrained': 1, 'Ġand': 1, 'Ġgenerate': 1, 'Ġtokens': 1})\n"
     ]
    }
   ],
   "source": [
    "word_freqs = Counter()\n",
    "for text in corpus:\n",
    "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    word_freqs += Counter([x[0] for x in words_with_offsets])\n",
    "print(word_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83cf009-f9ef-4c24-af4c-099859d0933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'C', 'F', 'H', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z', 'Ġ']\n"
     ]
    }
   ],
   "source": [
    "alphabet = sorted(reduce(lambda a, b : a.union(b), [set(x) for x in word_freqs.keys()]))\n",
    "print(alphabet)\n",
    "vocab = [\"<|endoftext|>\"] + alphabet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878976d4-0ab4-4810-967f-205bdd45e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', ['T', 'h', 'i', 's']),\n",
       " ('Ġis', ['Ġ', 'i', 's']),\n",
       " ('Ġthe', ['Ġ', 't', 'h', 'e'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = {word: [c for c in word] for word in word_freqs.keys()}\n",
    "list(splits.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "312666b4-9327-461b-9b3d-786849ab61d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('T', 'h'): 3\n",
      "('h', 'i'): 3\n",
      "('i', 's'): 5\n",
      "('Ġ', 'i'): 2\n",
      "('Ġ', 't'): 7\n",
      "('t', 'h'): 3\n"
     ]
    }
   ],
   "source": [
    "def compute_pair_freqs(splits):\n",
    "    pair_freqs = Counter()\n",
    "    for word, freq in word_freqs.items():\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "        for i in range(len(split) - 1):\n",
    "            pair = (split[i], split[i + 1])\n",
    "            pair_freqs[pair] += freq\n",
    "    return pair_freqs\n",
    "\n",
    "pair_freqs = compute_pair_freqs(splits)\n",
    "\n",
    "for i, key in enumerate(pair_freqs.keys()):\n",
    "    print(f\"{key}: {pair_freqs[key]}\")\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f742d1ac-58a8-4754-8ddb-65ef48a61578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ġ', 't') 7\n"
     ]
    }
   ],
   "source": [
    "best_pair = sorted(pair_freqs, key = lambda x : pair_freqs[x], reverse = True)[0]\n",
    "print(best_pair, pair_freqs[best_pair])\n",
    "merges = {(\"Ġ\", \"t\"): \"Ġt\"}\n",
    "vocab.append(\"Ġt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f132a4a3-b8dc-4c5b-a722-4c5e4f3b6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġt', 'r', 'a', 'i', 'n', 'e', 'd']\n"
     ]
    }
   ],
   "source": [
    "def merge_pair(a, b, splits):\n",
    "    for word in word_freqs:\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "\n",
    "        i = 0\n",
    "        while i < len(split) - 1:\n",
    "            if split[i] == a and split[i + 1] == b:\n",
    "                split = split[:i] + [a + b] + split[i + 2 :]\n",
    "            else:\n",
    "                i += 1\n",
    "        splits[word] = split\n",
    "    return splits\n",
    "\n",
    "splits = merge_pair(\"Ġ\", \"t\", splits)\n",
    "print(splits[\"Ġtrained\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "141e05b8-92bd-4c45-86eb-c609bde32782",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50\n",
    "\n",
    "while len(vocab) < vocab_size:\n",
    "    pair_freqs = compute_pair_freqs(splits)\n",
    "    best_pair = sorted(pair_freqs, key = lambda x : pair_freqs[x], reverse = True)[0]\n",
    "    splits = merge_pair(*best_pair, splits)\n",
    "    merges[best_pair] = best_pair[0] + best_pair[1]\n",
    "    vocab.append(best_pair[0] + best_pair[1])\n",
    "\n",
    "token_to_id = dict(zip(vocab, range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3efc2490-d582-492f-9ade-deb08a1fe37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    pre_tokenize_result = tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "    pre_tokenized_text = [word for word, offset in pre_tokenize_result]\n",
    "    splits = [[l for l in word] for word in pre_tokenized_text]\n",
    "    for pair, merge in merges.items():\n",
    "        for idx, split in enumerate(splits):\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                    split = split[:i] + [merge] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            splits[idx] = split\n",
    "    splits = reduce(lambda a, b : a+b, splits)\n",
    "    print(splits)\n",
    "    return [token_to_id[x] for x in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8297e33-3927-42ee-b904-7ba76fa1e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(token_ids):\n",
    "    id_to_token = dict(zip(token_to_id.values(), token_to_id.keys()))\n",
    "    return \"\".join([id_to_token[x] for x in token_ids]).replace(\"Ġ\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "703e1c3e-4732-4cb8-9c19-449d39bd9367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'Ġis', 'Ġ', 'n', 'o', 't', 'Ġa', 'Ġtoken', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[38, 44, 30, 19, 20, 24, 34, 42, 2]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenize(\"This is not a token.\")\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1f1f6f6-eaff-44ce-8d46-29b9491b0f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is not a token.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1f503-ff84-465c-8e92-0995b8743ab8",
   "metadata": {},
   "source": [
    "### Input Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2522dd00-c84d-4637-9acc-8376dffd13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import os\n",
    "import urllib.request\n",
    "input_file = \"../data/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = input_file\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d42410da-3540-4a89-8930-2b68a2e50fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, context_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of context_length\n",
    "        for i in range(0, len(token_ids) - context_length, stride):\n",
    "            input_chunk = token_ids[i:i + context_length]\n",
    "            target_chunk = token_ids[i + 1: i + context_length + 1] # Shift target by 1\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cca9f632-5057-458a-b961-32fc178e9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, context_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, context_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f384788-2e3f-4160-a708-cc7ffc6a9c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "context_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, context_length=context_length,\n",
    "    stride=context_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "851a9375-9745-4b4f-9d3e-6d6b78cc13a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([8, 4, 256]) \n",
      "\n",
      "Positional Embedding Shape: torch.Size([4, 256]) \n",
      "\n",
      "Input + Positional Embedding Shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tiktoken.get_encoding(\"gpt2\").n_vocab\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Input Shape:\", token_embeddings.shape, '\\n') # batch_size x context_length x output_dim\n",
    "\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Positional Embedding Shape:\", pos_embeddings.shape, '\\n')\n",
    "\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Input + Positional Embedding Shape:\", input_embeddings.shape) # Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd6bea-1bdb-4f10-8adb-d43d68a92e74",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291a74b4-9afb-4f37-9e6e-160d93731904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce60bba-9e37-4d1f-8ac1-f66668467060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_and_segments(tokens_a, tokens_b=None):\n",
    "    \"\"\"Get tokens of the BERT input sequence and their segment IDs.\"\"\"\n",
    "    tokens = ['<cls>'] + tokens_a + ['<sep>']\n",
    "    # 0 and 1 are marking segment A and B, respectively\n",
    "    segments = [0] * (len(tokens_a) + 2)\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<sep>']\n",
    "        segments += [1] * (len(tokens_b) + 1)\n",
    "    return tokens, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99525e07-8bf2-4883-aaaa-16188897ea15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 1.5738, -0.9070, -0.8343, -0.0515],\n",
       "         [-0.9063,  1.3813, -0.1734, -0.5101],\n",
       "         [-0.2838, -0.6132, -1.6051, -1.1009],\n",
       "         [ 1.0590,  0.5096,  0.7580,  0.4336],\n",
       "         [-0.7619,  0.3362, -0.1701,  1.7476]]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.randn(1, 5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa611775-834e-4efe-b94c-15942169e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEncoder(nn.Module):\n",
    "    \"\"\"BERT encoder.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n",
    "                 num_blks, dropout, max_len=1000, **kwargs):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.segment_embedding = nn.Embedding(2, num_hiddens)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_blks):\n",
    "            self.blks.add_module(f\"{i}\", d2l.TransformerEncoderBlock(\n",
    "                num_hiddens, ffn_num_hiddens, num_heads, dropout, True))\n",
    "        # In BERT, positional embeddings are learnable, thus we create a\n",
    "        # parameter of positional embeddings that are long enough\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n",
    "                                                      num_hiddens))\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens):\n",
    "        # Shape of `X` remains unchanged in the following code snippet:\n",
    "        # (batch size, max sequence length, `num_hiddens`)\n",
    "        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n",
    "        X = X + self.pos_embedding[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a0f3c6-7145-438b-925b-25848a092945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4\n",
    "ffn_num_input, num_blks, dropout = 768, 2, 0.2\n",
    "encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n",
    "                      num_blks, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ac27c5-8dce-4244-88ee-525cc8fb56e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.randint(0, vocab_size, (2, 8)) # 2 sequences with 8 tokens each\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = encoder(tokens, segments, None) \n",
    "encoded_X.shape # hidden/embedding dimension is 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2931d3-2918-4adf-8254-b3bed43f655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskLM(nn.Module):\n",
    "    \"\"\"The masked language model task of BERT.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, **kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "        self.mlp = nn.Sequential(nn.LazyLinear(num_hiddens),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LayerNorm(num_hiddens),\n",
    "                                 nn.LazyLinear(vocab_size))\n",
    "\n",
    "    def forward(self, X, pred_positions):\n",
    "        num_pred_positions = pred_positions.shape[1]\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        batch_size = X.shape[0]\n",
    "        batch_idx = torch.arange(0, batch_size)\n",
    "        # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then\n",
    "        # `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`\n",
    "        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n",
    "        masked_X = X[batch_idx, pred_positions]\n",
    "        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n",
    "        mlm_Y_hat = self.mlp(masked_X)\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7c3bf1-203f-47b0-b9e1-15e309af3981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm = MaskLM(vocab_size, num_hiddens)\n",
    "mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])\n",
    "mlm_Y_hat = mlm(encoded_X, mlm_positions)\n",
    "mlm_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f63e17-cec4-4d2f-abb4-e70ec5955f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))\n",
    "mlm_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f70d0a5-784b-47d3-9db2-4e2919969709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextSentencePred(nn.Module):\n",
    "    \"\"\"The next sentence prediction task of BERT.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NextSentencePred, self).__init__(**kwargs)\n",
    "        self.output = nn.LazyLinear(2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # `X` shape: (batch size, `num_hiddens`)\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2eb345-2838-4301-b816-e3a3b14fe13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch by default will not flatten the tensor as seen in mxnet where, if\n",
    "# flatten=True, all but the first axis of input data are collapsed together\n",
    "encoded_X = torch.flatten(encoded_X, start_dim=1)\n",
    "# input_shape for NSP: (batch size, `num_hiddens`)\n",
    "nsp = NextSentencePred()\n",
    "nsp_Y_hat = nsp(encoded_X)\n",
    "nsp_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91230e58-1d84-4db6-8304-07c415be55e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsp_y = torch.tensor([0, 1])\n",
    "nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "nsp_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55fd1077-d724-451e-b336-e7a1d8013b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModel(nn.Module):\n",
    "    \"\"\"The BERT model.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n",
    "                 num_heads, num_blks, dropout, max_len=1000):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,\n",
    "                                   num_heads, num_blks, dropout,\n",
    "                                   max_len=max_len)\n",
    "        self.fc = nn.Sequential(nn.LazyLinear(num_hiddens),\n",
    "                                    nn.Tanh())\n",
    "        self.mlm = MaskLM(vocab_size, num_hiddens)\n",
    "        self.nsp = NextSentencePred()\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):\n",
    "        encoded_X = self.encoder(tokens, segments, valid_lens)\n",
    "        if pred_positions is not None:\n",
    "            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n",
    "        else:\n",
    "            mlm_Y_hat = None\n",
    "        # encoded_X is of shape (batch_size, seq_len, num_hiddens)\n",
    "        nsp_input = self.fc(encoded_X[:, 0, :])\n",
    "        nsp_Y_hat = self.nsp(nsp_input)\n",
    "        return encoded_X, mlm_Y_hat, nsp_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f665f07e-eced-4f33-a76e-ac3a56662230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads input in the form we want it\n",
    "# Processing is done in https://d2l.ai/chapter_natural-language-processing-pretraining/bert-dataset.html, this is important to understand but we skip for brevity\n",
    "\n",
    "import os\n",
    "import random\n",
    "batch_size, max_len = 512, 64\n",
    "data_dir = '../data/WikiText' # Download wikitext-2-v1 from https://www.kaggle.com/datasets/bestwater/wikitext-2-v1 to this directory\n",
    "paragraphs = d2l._read_wiki(data_dir)\n",
    "train_set = d2l._WikiTextDataset(paragraphs, max_len)\n",
    "train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                    shuffle=True, num_workers=d2l.get_dataloader_workers())\n",
    "vocab = train_set.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36d42680-d169-4122-af5b-e7ce0f63986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = d2l.BERTModel(len(vocab), num_hiddens=128,\n",
    "                    ffn_num_hiddens=256, num_heads=2, num_blks=2, dropout=0.2)\n",
    "devices = d2l.try_all_gpus()\n",
    "loss = nn.CrossEntropyLoss(reduction = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56285172-bad2-458e-b19b-87032697d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_batch_loss_bert(net, loss, vocab_size, tokens_X,\n",
    "                         segments_X, valid_lens_x,\n",
    "                         pred_positions_X, mlm_weights_X,\n",
    "                         mlm_Y, nsp_y):\n",
    "    # Forward pass\n",
    "    _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,\n",
    "                                  valid_lens_x.reshape(-1),\n",
    "                                  pred_positions_X)\n",
    "    # Compute masked language model loss\n",
    "    # mlm_weights_X here prevents us from computing loss on padded tokens\n",
    "    mlm_l = loss(mlm_Y_hat.reshape(-1, vocab_size), mlm_Y.reshape(-1)) *\\\n",
    "    mlm_weights_X.reshape(-1, 1)\n",
    "    mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)\n",
    "    # Compute next sentence prediction loss\n",
    "    nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "    l = mlm_l + nsp_l\n",
    "    return mlm_l, nsp_l, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e977623-8f8f-4d31-8f3f-85b32b304e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(train_iter, net, loss, vocab_size, devices, num_steps):\n",
    "    net(*next(iter(train_iter))[:4])\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    step, timer = 0, d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='step', ylabel='loss',\n",
    "                            xlim=[1, num_steps], legend=['mlm', 'nsp'])\n",
    "    # Sum of masked language modeling losses, sum of next sentence prediction\n",
    "    # losses, no. of sentence pairs, count\n",
    "    metric = d2l.Accumulator(4)\n",
    "    num_steps_reached = False\n",
    "    device = torch.device('cpu') if not devices else devices[0]\n",
    "    while step < num_steps and not num_steps_reached:\n",
    "        for tokens_X, segments_X, valid_lens_x, pred_positions_X,\\\n",
    "            mlm_weights_X, mlm_Y, nsp_y in train_iter:\n",
    "            tokens_X = tokens_X.to(device)\n",
    "            segments_X = segments_X.to(device)\n",
    "            valid_lens_x = valid_lens_x.to(device) # This marks the padded indices, to be used in masking in self-attention\n",
    "            pred_positions_X = pred_positions_X.to(device)\n",
    "            mlm_weights_X = mlm_weights_X.to(device) # This \n",
    "            mlm_Y, nsp_y = mlm_Y.to(device), nsp_y.to(device)\n",
    "            trainer.zero_grad()\n",
    "            timer.start()\n",
    "            mlm_l, nsp_l, l = _get_batch_loss_bert(\n",
    "                net, loss, vocab_size, tokens_X, segments_X, valid_lens_x,\n",
    "                pred_positions_X, mlm_weights_X, mlm_Y, nsp_y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            metric.add(mlm_l, nsp_l, tokens_X.shape[0], 1)\n",
    "            timer.stop()\n",
    "            animator.add(step + 1,\n",
    "                         (metric[0] / metric[3], metric[1] / metric[3]))\n",
    "            step += 1\n",
    "            if step == num_steps:\n",
    "                num_steps_reached = True\n",
    "                break\n",
    "\n",
    "    print(f'MLM loss {metric[0] / metric[3]:.3f}, '\n",
    "          f'NSP loss {metric[1] / metric[3]:.3f}')\n",
    "    print(f'{metric[2] / timer.sum():.1f} sentence pairs/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40397aae-1a35-4079-9c7c-08c5d97e52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert(train_iter, net, loss, len(vocab), devices, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6cf627dc-3361-49bb-acb9-2c2058f609af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_encoding(net, tokens_a, tokens_b=None):\n",
    "    tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "    device = torch.device('cpu') if not devices else devices[0]\n",
    "    token_ids = torch.tensor(vocab[tokens], device=device).unsqueeze(0)\n",
    "    segments = torch.tensor(segments, device=device).unsqueeze(0)\n",
    "    valid_len = torch.tensor(len(tokens), device=device).unsqueeze(0)\n",
    "    encoded_X, _, _ = net(token_ids, segments, valid_len)\n",
    "    return encoded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e93a559f-d3a1-4fe9-867b-9cbdbbdc8ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 128]),\n",
       " torch.Size([1, 128]),\n",
       " tensor([0.0901, 0.3364, 0.9336], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_a = ['a', 'crane', 'is', 'flying']\n",
    "encoded_text = get_bert_encoding(net, tokens_a)\n",
    "# Tokens: '<cls>', 'a', 'crane', 'is', 'flying', '<sep>'\n",
    "encoded_text_cls = encoded_text[:, 0, :]\n",
    "encoded_text_crane = encoded_text[:, 2, :]\n",
    "encoded_text.shape, encoded_text_cls.shape, encoded_text_crane[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faa7827a-7e3d-43fb-b000-8b3baadb9735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 128]),\n",
       " torch.Size([1, 128]),\n",
       " tensor([0.3325, 0.0918, 1.0524], grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_a, tokens_b = ['a', 'crane', 'driver', 'came'], ['he', 'just', 'left']\n",
    "encoded_pair = get_bert_encoding(net, tokens_a, tokens_b)\n",
    "# Tokens: '<cls>', 'a', 'crane', 'driver', 'came', '<sep>', 'he', 'just',\n",
    "# 'left', '<sep>'\n",
    "encoded_pair_cls = encoded_pair[:, 0, :]\n",
    "encoded_pair_crane = encoded_pair[:, 2, :]\n",
    "encoded_pair.shape, encoded_pair_cls.shape, encoded_pair_crane[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4c290-ca2b-4402-9435-340d2d953ded",
   "metadata": {},
   "source": [
    "Notice how the first 3 values (out of 128) of \"crane\" is now different due to context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
