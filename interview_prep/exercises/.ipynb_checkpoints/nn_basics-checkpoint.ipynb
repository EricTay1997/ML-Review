{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776b273c-4c3d-42b3-a844-9df49d9a57ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "863059eb-d61a-4260-9e42-9652502f44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ccfbb2e-1f75-429c-af8d-992aced36625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "# Continuous\n",
    "np.random.seed(42)  \n",
    "m = 100  \n",
    "X = 2 * np.random.rand(m, 1)  \n",
    "y = 4 + 3 * X + np.random.randn(m, 1)  \n",
    "X_b = add_dummy_feature(X)  \n",
    "X_new = np.array([[0], [2]])\n",
    "\n",
    "# Categorical\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y_bin = (iris.target == 2) \n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028abaa-138d-4aad-97b0-f3c46bfeab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern is\n",
    "# model()\n",
    "# model.fit(X_train, y_train)\n",
    "# model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44cc38cb-f6fc-49f0-90ad-5f0e6d04e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "pred_lin = lin_reg.predict(X_new)\n",
    "\n",
    "ridge_reg = Ridge(alpha=100, solver=\"cholesky\")\n",
    "ridge_reg.fit(X, y)\n",
    "pred_ridge = ridge_reg.predict(X_new)\n",
    "\n",
    "lasso_reg = Lasso(alpha=100/(2*len(X)))\n",
    "lasso_reg.fit(X, y)\n",
    "pred_lasso = lasso_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "169c62f3-8d3f-436d-b500-302603893717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 47,  3],\n",
       "       [ 0,  2, 48]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X, y) # allows for multi-class\n",
    "y_pred = log_reg.predict(X)\n",
    "cm = confusion_matrix(y, y_pred) \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "131aaf76-6270-4e7d-91aa-185182b8faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "svm_clf1 = LinearSVC(C=1, max_iter=10_000, dual=True, random_state=42) # linear kernel, can use SVC for rbf kernel\n",
    "# model_loss = C*classification_loss + penalty, so lower C means higher regularization\n",
    "scaled_svm_clf1 = make_pipeline(scaler, svm_clf1)\n",
    "scaled_svm_clf1.fit(X, y) # allows for multi-class\n",
    "scaled_svm_clf1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6466ee8b-d74c-42b7-8d06-8a0c35fdfeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)\n",
    "tree_clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523b33a-43ea-4a07-a827-633c4f23709b",
   "metadata": {},
   "source": [
    "# NN Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772bef86-c24c-428e-8428-7b18d8496bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088351f9-b45e-4ca5-ac95-43a11eaf1f58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ddebfeb-dd5e-4c0b-9ec0-c6b3b4383493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.data = None\n",
    "        self.label = None\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3641ac6-7fb9-4be2-8268-ad146197459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, act_fn = nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = act_fn\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    # One layer and no activation for glm\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6dd6fb-a888-4ec3-b36c-64f894922f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.reshape(-1,)\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61763efd-c9d2-4c61-889b-e8596ca1d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() \n",
    "    true_preds, num_preds = 0., 0.\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            pred_labels = (torch.sigmoid(preds) > 0.5).int().reshape(-1)\n",
    "            true_preds += (pred_labels == data_labels).sum().float()\n",
    "            num_preds += data_labels.shape[0]\n",
    "\n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd121db-7c90-47ed-a706-eb083554e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\") if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2780019e-c1f4-44b0-8f5d-219d4aa1ccee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce31e0ea7a2f49e4a23caa74cff7eaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'linear1.weight': tensor([[-0.6186, -1.2413],\n",
      "        [ 2.4791,  2.3084],\n",
      "        [-1.9578,  2.8000],\n",
      "        [ 3.2432, -2.6608]], device='mps:0'), 'linear1.bias': tensor([ 1.3746, -0.7270,  0.7655,  1.2364], device='mps:0'), 'linear2.weight': tensor([[ 2.0459,  3.4998, -3.6495, -4.2671]], device='mps:0'), 'linear2.bias': tensor([0.8146], device='mps:0')})\n",
      "Accuracy of the model: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor_str.py:145: UserWarning: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729646995093/work/aten/src/ATen/native/mps/operations/Indexing.mm:361.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "set_seed(1)\n",
    "# Change this to MSE for linear regression\n",
    "# Change this to CrossEntropyLoss for multi-category, but rmb to change num_outputs to number of classes\n",
    "loss_module = nn.BCEWithLogitsLoss()\n",
    "train_dataset = XORDataset(size=2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataset = XORDataset(size=500)\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)\n",
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "train_model(model, optimizer, train_data_loader, loss_module)\n",
    "\n",
    "# Save model\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)\n",
    "# torch.save(state_dict, \"our_model.tar\")\n",
    "# state_dict = torch.load(\"our_model.tar\")\n",
    "# new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "# new_model.load_state_dict(state_dict)\n",
    "\n",
    "eval_model(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cd243-9670-4841-807c-7b2816aadb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "# define dataloaders\n",
    "# define model\n",
    "# define device and set seed\n",
    "# define optimizer\n",
    "# define loss module\n",
    "# model.to(device)\n",
    "# model.train()\n",
    "# for each epoch\n",
    "# for data_input, data_label in data_loader:\n",
    "# predict\n",
    "# loss\n",
    "# zero\n",
    "# loss.backward\n",
    "# optimizer.step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f536113-1d68-4c73-ac0e-50184edb9f86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f72aa218-1f56-4fe2-8537-2c88531a0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "    def __init__(self, size, std = 0.1):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.data = torch.randint(2, size = (size, 2), dtype = torch.float32)\n",
    "        self.targets = (self.data.sum(axis = 1) == 1).to(torch.float32)\n",
    "        self.data += torch.randn(self.data.shape)*std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd698384-807e-4bef-8967-a071d630695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_inputs, num_hidden, num_classes, act_fn = nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = act_fn\n",
    "        self.linear2 = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c26bb5b-f893-4ed6-9598-964d2cd28ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d128cdaf-5408-43cf-ab34-f76cedbedc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (act_fn): Tanh()\n",
       "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "set_seed(42)\n",
    "train_dataset = XORDataset(2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "model = SimpleClassifier(2, 4, 1)\n",
    "device = torch.device(\"mps\") if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5113f71b-45d9-4086-b480-75aa8f3d9718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "50.32\n",
      "48.6\n",
      "47.96\n",
      "46.28\n",
      "48.96\n",
      "47.64\n",
      "49.64\n",
      "49.96\n",
      "50.08\n",
      "49.36\n",
      "51.8\n",
      "50.72\n",
      "51.64\n",
      "51.96\n",
      "52.12\n",
      "51.36\n",
      "56.36\n",
      "51.52\n",
      "50.8\n",
      "52.16\n",
      "50.92\n",
      "51.32\n",
      "51.2\n",
      "50.76\n",
      "51.44\n",
      "50.8\n",
      "52.32\n",
      "55.16\n",
      "62.76\n",
      "78.48\n",
      "89.4\n",
      "97.4\n",
      "99.4\n",
      "99.8\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "set_seed(42)\n",
    "train_dataset = XORDataset(2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "model = SimpleClassifier(2, 4, 1)\n",
    "device = torch.device(\"mps\") if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    sum_correct = 0\n",
    "    sum_data_points = 0\n",
    "    for data_input, data_label in train_data_loader:\n",
    "        data_input = data_input.to(device)\n",
    "        data_label = data_label.to(device)\n",
    "        pred = model(data_input).flatten()\n",
    "        loss = loss_fn(pred, data_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_data_points += len(data_input)\n",
    "        sum_correct += ((pred > 0) == data_label).sum()\n",
    "    print(np.round((100*sum_correct/sum_data_points).cpu().item(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe98514-d36c-4915-8249-00b8552ab145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4d81970a-b391-4ecf-ab26-f571e675f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Callable, Iterator, Self\n",
    "import math\n",
    "\n",
    "class CustomDataLoader: # (Generic[T_co])\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: torch.utils.data.Dataset[torch.Tensor], # torch.utils.data.Dataset[T_co]\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        collate_fn: Optional[Callable] = None\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        # self.collate_fn = collate_fn if collate_fn is not None else default_collate\n",
    "        self.sampler = sampler(dataset) if sampler is not None else None\n",
    "        self.dataset_len = len(dataset)\n",
    "        self.num_batches = math.ceil(self.dataset_len / self.batch_size)\n",
    "        self.batches = None\n",
    "        \n",
    "    def __iter__(self) -> Iterator[torch.Tensor]: # Iterator[List[T_co]]\n",
    "        if self.shuffle:\n",
    "            indices = torch.randperm(self.dataset_len).tolist()\n",
    "        else:\n",
    "            indices = list(range(self.dataset_len))\n",
    "        # indices = list(self.sampler)\n",
    "        batches = []\n",
    "        for i in range(0, self.dataset_len, self.batch_size):\n",
    "            batch_indices = indices[i:i + self.batch_size]\n",
    "            batches.append(batch_indices)\n",
    "        self.batches = batches\n",
    "        return _DataLoaderIter(self)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.num_batches\n",
    "\n",
    "class _DataLoaderIter:    \n",
    "    def __init__(self, loader: CustomDataLoader):\n",
    "        self.loader = loader\n",
    "        self.current_batch = 0\n",
    "    \n",
    "    def __iter__(self) -> Self: # '_DataLoaderIter'\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> torch.Tensor: # List[T_co]\n",
    "        if self.current_batch >= len(self.loader.batches):\n",
    "            raise StopIteration\n",
    "        batch_indices = self.loader.batches[self.current_batch]\n",
    "        self.current_batch += 1\n",
    "        batch_data = [self.loader.dataset[idx] for idx in batch_indices]\n",
    "        # print(batch_data)\n",
    "        # batch = torch.stack(batch_data, 0) # Assume tensor\n",
    "        # batch = self.loader.collate_fn(batch_data)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0294ca1-770d-42bb-9830-d393bcc007e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Mapping, Sequence\n",
    "def default_collate(batch): # batch: List[T_co]\n",
    "    elem = batch[0]\n",
    "    if isinstance(elem, torch.Tensor):\n",
    "        return torch.stack(batch, 0)\n",
    "    elif isinstance(elem, (str, bytes)):\n",
    "        return batch\n",
    "    elif isinstance(elem, Mapping):\n",
    "        return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
    "    elif isinstance(elem, Sequence) and not isinstance(elem, (str, bytes)): # X, y\n",
    "        transposed = zip(*batch)\n",
    "        return [default_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16431440-8f9d-49f1-9bd9-9085f51dec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler: # Generic[T_co]\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        raise NotImplementedError\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_source)\n",
    "\n",
    "class SequentialSampler: # (Sampler[T_co])\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        return iter(range(len(self.data_source)))\n",
    "\n",
    "class RandomSampler: (Sampler[T_co])\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        return iter(torch.randperm(len(self.data_source)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d61aef-8fbe-492b-b8b1-46ec237be394",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "generator.manual_seed(self.seed)\n",
    "indices = torch.randperm(self.dataset_len, generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6d1a8-df5f-41d7-85a2-960ca26d602f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "81efbabf-2fca-47e4-92a9-15c1c2698ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = self.__class__.__name__\n",
    "\n",
    "class Identity(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x * (x > 0)\n",
    "\n",
    "class Tanh(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return (torch.exp(x) - torch.exp(-x))/(torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return 1/(1 + torch.exp(-x))\n",
    "\n",
    "class SoftPlus(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return torch.log(1 + np.exp(x))\n",
    "\n",
    "class ELU(ActivationFunction):\n",
    "    def __init__(self, alpha = 1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.where(x >= 0, x, self.alpha*(torch.exp(x)-1))\n",
    "\n",
    "class GeLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1 + torch.tanh(torch.tensor(2/torch.pi)*(x + 0.044715*x**3)))\n",
    "\n",
    "class SiLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec2d8d-f51e-4daa-af15-bcf2f2d472f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23431610-2c62-401e-bf47-2eace6d232e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module): \n",
    "    \n",
    "    def __init__(self, act_fn = nn.ReLU(), input_size=784, num_classes=10, hidden_sizes=[512, 256, 256, 128]):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + hidden_sizes\n",
    "        for layer_index in range(1, len(layer_sizes)):\n",
    "            layers += [nn.Linear(layer_sizes[layer_index-1], layer_sizes[layer_index]),\n",
    "                       act_fn]\n",
    "        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n",
    "        self.layers = nn.Sequential(*layers) \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.endswith(\"bias\"):\n",
    "                nn.init.zeros_(param)\n",
    "            else:\n",
    "                # nn.init.normal_(param, std = np.sqrt(2/(param.shape[0] + param.shape[1]))) # xavier\n",
    "                nn.init.normal_(param, std = np.sqrt(2/param.shape[1])) # kaiming\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e7b50-b574-4f27-be99-fa7550c395d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "06ec50eb-24f4-4bbf-914a-1839d65adaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerTemplate:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()\n",
    "                p.grad.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                self.update_param(p)\n",
    "            \n",
    "    def update_param(self, p):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "13185628-f7a9-450f-a116-b0e62197ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(OptimizerTemplate):\n",
    "    def update_param(self, p):\n",
    "        p_update = -self.lr*p.grad\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "333351ab-3e51-41cb-8d8f-bc04b56c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, momentum = 0.0):\n",
    "        super().__init__()\n",
    "        self.beta1 = momentum\n",
    "        self.param_momentum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "    \n",
    "    def update_param(self, p):\n",
    "        self.param_momentum[p] = p.grad + self.beta1*self.param_momentum[p]\n",
    "        p_update = -self.lr * self.param_momentum[p]\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ab29fc5e-7a46-43f7-ba06-01198340398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, epsilon = 1e-8):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_sq_grad_sum[p].add_(p.grad**2)\n",
    "        p_update = -self.lr * p.grad / torch.sqrt(self.param_sq_grad_sum[p] + self.epsilon)\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4079e675-fcc5-4c75-bb80-ca6bdc33f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSProp(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, epsilon = 1e-8, beta2 = 0.999):\n",
    "        super().__init__()\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_sq_grad_sum[p] = self.beta2*self.param_sq_grad_sum[p] + (1-self.beta2)*(p.grad**2)\n",
    "        p_update = -self.lr * p.grad / torch.sqrt(self.param_sq_grad_sum[p] + self.epsilon)\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d08ddac0-8b9d-48ef-81ff-d8b560ba71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaDelta(OptimizerTemplate):\n",
    "    def __init__(self, params, lr = 1.0, epsilon = 1e-8, beta2 = 0.999): \n",
    "        super().__init__()\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.param_delta = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_sq_grad_sum[p] = self.beta2*self.param_sq_grad_sum[p] + (1-self.beta2)*(p.grad**2)\n",
    "        ada_lr = torch.sqrt(self.param_delta[p] + self.epsilon)\n",
    "        p_update = - ada_lr * p.grad / torch.sqrt(self.param_sq_grad_sum[p] + self.epsilon)\n",
    "        p.add_(p_update)\n",
    "        self.param_delta[p] = self.beta2*self.param_delta[p] + (1-self.beta2)*(p_update**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7f342c1e-b603-4734-a932-cfa6e5611c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, epsilon = 1e-8, beta1 = 0.99, beta2 = 0.999):\n",
    "        super().__init__()\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.param_step = {p : 0 for p in self.params}\n",
    "        self.param_momentum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_step[p] += 1\n",
    "        self.param_momentum[p] = self.beta1*self.param_momentum[p] + (1-self.beta1)*p.grad\n",
    "        self.param_sq_grad_sum[p] = self.beta2*self.param_sq_grad_sum[p] + (1-self.beta2)*(p.grad**2)\n",
    "        beta1_norm = 1 - self.beta1**self.param_step[p]\n",
    "        beta2_norm = 1 - self.beta2**self.param_step[p]\n",
    "        p_update = -self.lr * (self.param_momentum[p]/beta1_norm) / (torch.sqrt(self.param_sq_grad_sum[p]/beta2_norm) + self.epsilon)\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddceea3-3a33-4e03-97c2-2fdd37ed7195",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dot Product Attention / Multi-Head Self Attention / Cross-Attention / Grouped Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "23ddfe0e-20f4-40ac-b1e7-9b28e5d040cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = k.size()[-1]\n",
    "    attn_logits = torch.einsum('bhij,bhkj->bhik', q, k)\n",
    "    attn_logits = attn_logits / (d_k**0.5)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim = -1)\n",
    "    values_added = torch.einsum('bhij,bhjk->bhik', attention, v)\n",
    "    return values_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a9738afd-eca6-4634-bccc-23d93e83df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, max_context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.qkv = nn.Linear(embed_dim, embed_dim*3, bias = qkv_bias)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\", torch.triu(torch.ones(max_context_length, max_context_length), diagonal = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        # b, n, 3*embed_dim\n",
    "        qkv = self.qkv(x) \n",
    "        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
    "        # q is of shape b,h,n,d\n",
    "        q, k, v = qkv.permute(2, 0, 3, 1, 4)\n",
    "        attention = torch.einsum(\"bhij,bhkj->bhik\", q, k)\n",
    "        attention /= torch.sqrt(self.head_dim)\n",
    "        attention = attention.masked_fill(self.causal_mask[:seq_len, :seq_len] == 1, -torch.inf)\n",
    "        attention = torch.softmax(attention, dim = -1)\n",
    "        attention = self.dropout(attention)\n",
    "        delta_x = torch.einsum(\"bhij,bhjk->bhik\", attention, v)\n",
    "        # previously, delta_x is of shape b,h,n,d\n",
    "        delta_x = delta_x.transpose(1,2).reshape(batch_size, seq_len, embed_dim)\n",
    "        delta_x = self.o_proj(delta_x)\n",
    "        return delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119cef6-5361-4062-b6c5-706cf366b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very similar, except that y cross_dim and seq_len may be different\n",
    "# Also remove causal mask\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, cross_dim, num_heads, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias = qkv_bias)\n",
    "        self.k_proj = nn.Linear(cross_dim, embed_dim, bias = qkv_bias)\n",
    "        self.v_proj = nn.Linear(cross_dim, embed_dim, bias = qkv_bias)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        # b, n, embed_dim\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(y)\n",
    "        v = self.v_proj(y)\n",
    "\n",
    "        # decoder seq_len can be different from encoder seq_len\n",
    "        q = q.reshape(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        k = k.reshape(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        v = v.reshape(batch_size, -1, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        attention = torch.einsum(\"bhij,bhkj->bhik\", q, k)\n",
    "        attention /= torch.sqrt(self.head_dim)\n",
    "        attention = torch.softmax(attention, dim = -1)\n",
    "        attention = self.dropout(attention)\n",
    "        delta_x = torch.einsum(\"bhij,bhjk->bhik\", attention, v)\n",
    "        # previously, delta_x is of shape b,h,n,d\n",
    "        delta_x = delta_x.transpose(1,2).reshape(batch_size, seq_len, embed_dim)\n",
    "        delta_x = self.o_proj(delta_x)\n",
    "        return delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca735f38-7ba0-49a9-8c19-a49eb7914665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we remove bias and dropout\n",
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, max_context_length, num_heads, num_kv_heads, dtype = None):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "        assert num_heads % num_kv_heads == 0, \"num_heads is indivisible by num_kv_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_heads = num_kv_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.q_to_k_ratio = num_heads // num_kv_heads\n",
    "        self.qkv = nn.Linear(embed_dim, embed_dim + 2 * num_kv_heads * self.head_dim, bias = False, dtype = dtype)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim, bias = False)\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\", torch.triu(torch.ones(max_context_length, max_context_length), diagonal = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        q = qkv[:, :, :embed_dim].reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        k, v = qkv[:, :, embed_dim:].reshape(batch_size, seq_len, 2, self.num_kv_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "        k = k.repeat_interleave(self.q_to_k_ratio, dim = 1)\n",
    "        v = v.repeat_interleave(self.q_to_k_ratio, dim = 1)\n",
    "\n",
    "        attention = torch.einsum(\"bhij,bhkj->bhik\", q, k)\n",
    "        attention /= k.shape[-1]**0.5\n",
    "        attention = attention.masked_fill(self.causal_mask[:seq_len, :seq_len] == 1, -torch.inf)\n",
    "        attention = torch.softmax(attention, dim = -1)\n",
    "        delta_x = torch.einsum(\"bhij,bhjk->bhik\", attention, v)\n",
    "        delta_x = delta_x.transpose(1,2).reshape(batch_size, seq_len, embed_dim)\n",
    "        delta_x = self.o_proj(delta_x)\n",
    "        return delta_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf553476-42d2-4166-b2d7-d14e28059301",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "00552396-b468-47bf-92b8-4bfba7fd676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False,      # Query-Key-Value bias\n",
    "    \"std\": 0.02\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "22eb245a-5011-44c8-b562-faa3f123cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_embedding = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_embedding = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.final_linear = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
    "        self.tok_embedding.weight = self.final_linear.weight # weight_tying\n",
    "\n",
    "        # init\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('proj.weight'):\n",
    "                nn.init.normal_(p, std = cfg[\"std\"]/((2*cfg[\"n_layers\"])**0.5))\n",
    "            elif pn.endswith('weight'):\n",
    "                nn.init.normal_(p, std = cfg[\"std\"])\n",
    "            elif pn.endswith('bias'):\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        tok_embeds = self.tok_embedding(x)\n",
    "        pos_embeds = self.pos_embedding(torch.arange(seq_len, device = x.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.dropout(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.final_linear(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6e47d754-29d4-4b0b-a7fc-df93642e5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False)\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        return norm_x*self.scale + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "afac0be2-dbbf-4f66-813d-64e6d32e1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(cfg)\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        orig_x = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.dropout(x)\n",
    "        x += orig_x\n",
    "\n",
    "        orig_x = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x)\n",
    "        x += orig_x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b85d63da-f4a4-45b7-a4ac-08737fc7a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        assert cfg[\"emb_dim\"] % cfg[\"n_heads\"] == 0, \"emb_dim is indivisible by n_heads\"\n",
    "        self.num_heads = cfg[\"n_heads\"]\n",
    "        self.head_dim = cfg[\"emb_dim\"] // cfg[\"n_heads\"]\n",
    "        self.qkv = nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"]*3, bias = cfg[\"qkv_bias\"])\n",
    "        self.o_proj = nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        self.att_dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\", torch.triu(torch.ones(cfg[\"context_length\"], cfg[\"context_length\"]), diagonal = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, emb_dim = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
    "        q, k, v = qkv.permute(2, 0, 3, 1, 4)\n",
    "        attention = torch.einsum('bhij,bhkj->bhik', q, k)\n",
    "        attention /= k.shape[-1]**0.5\n",
    "        attention = attention.masked_fill(self.causal_mask[:seq_len, :seq_len] == 1, -torch.inf)\n",
    "        attention = torch.softmax(attention, dim = -1)\n",
    "        attention = self.att_dropout(attention)\n",
    "        delta_x = torch.einsum('bhij,bhjk->bhik', attention, v)\n",
    "        delta_x = delta_x.transpose(1,2)\n",
    "        delta_x = delta_x.reshape(batch_size, seq_len, emb_dim)\n",
    "        delta_x = self.o_proj(delta_x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "296e1706-e759-420d-9408-853ce3292b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"]*4)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.proj = nn.Linear(cfg[\"emb_dim\"]*4, cfg[\"emb_dim\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843c78e-f700-4745-b30a-94cee107e74e",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "- Fixed PE, RoPE\n",
    "- LayerNorm/RMSNorm\n",
    "- Pre/Post Layer norm\n",
    "- GeLU/SwiGLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522241b-66b0-40e1-8298-dadd9c02b1b6",
   "metadata": {},
   "source": [
    "### GELU/SwiGLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8ac6c0bf-f4dd-4a3c-a67c-afa3c1a1af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "be19905c-3501-451a-bcc5-27110041ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype = cfg[\"dtype\"], bias = False)\n",
    "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype = cfg[\"dtype\"], bias = False)\n",
    "        self.proj = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype = cfg[\"dtype\"], bias = False)\n",
    "        self.silu = SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x)\n",
    "        x = self.silu(x_fc1) * x_fc2\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502cd3b-975b-46d6-b17c-6a83af6205dd",
   "metadata": {},
   "source": [
    "### RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8a5d2064-f3a9-4383-810f-f491c020355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps = 1e-05):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim = -1, keepdim = True)\n",
    "        var = x.var(dim = -1, keepdim = True, unbiased = False)\n",
    "        x = (x-mean)/torch.sqrt(var + self.eps)\n",
    "        return x*self.scale + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "717033bf-cc4d-47f6-bb0f-a7a93b3c1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps = 1e-05):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        rms = torch.sqrt(x.pow(2).mean(dim = -1, keepdim = True) + self.eps)\n",
    "        x = self.scale*(x/rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccbaf4-ad36-4535-baa2-541456125838",
   "metadata": {},
   "source": [
    "### Pre/Post Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d83a6c3c-0045-4e58-bd6a-67aa3b882b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttn(cfg)\n",
    "        self.ffn = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward_pre(self, x): \n",
    "        orig_x = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.dropout(x)\n",
    "        x += orig_x\n",
    "\n",
    "        orig_x = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        x += orig_x\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward_post(self, x): # Also one more thing - in the GPTModel, we no longer need the final norm\n",
    "        orig_x = x\n",
    "        x = self.att(x)\n",
    "        x = self.dropout(x)\n",
    "        x += orig_x\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        orig_x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout(x)\n",
    "        x += orig_x\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806f8b1-fc8d-4d8d-89c6-0fd8e0bcab67",
   "metadata": {},
   "source": [
    "### PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "ca32862a-7fc7-4342-beef-2002e7245db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb:\n",
    "    @staticmethod\n",
    "    def generate_sinusoidal_pos_emb(ctx_len, emb_dim):\n",
    "        pe = torch.zeros((ctx_len, emb_dim))\n",
    "        position = torch.arange(0, ctx_len, dtype=torch.float).unsqueeze(1) # (ctx_len, 1)\n",
    "        div_term = torch.tensor(10000.0).pow(torch.arange(0, emb_dim, 2).float()/emb_dim).unsqueeze(0) # (1, emb_dim)\n",
    "        pe[:, 0::2] = torch.sin(position / div_term)\n",
    "        pe[:, 1::2] = torch.cos(position / div_term)\n",
    "        return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "cfcaea7a-2c57-4b4f-ab35-7b45985921ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_embedding = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.learned_pos_embedding = nn.Embedding(cfg[\"ctx_length\"], cfg[\"emb_dim\"])\n",
    "        sin_pos_emb = SinusoidalPosEmb.generate_sinusoidal_pos_emb(cfg[\"ctx_length\"], cfg[\"emb_dim\"])\n",
    "        self.register_buffer('sin_pos_emb', sin_pos_emb, persistent = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        learned_pos_emb = self.learned_pos_embedding(torch.arange(seq_len, device = x.device))\n",
    "        sin_pos_emb = self.sin_pos_emb[:seq_len]\n",
    "        tok_embeds = self.tok_embedding(x)\n",
    "        x = tok_embeds + sin_pos_emb # add with broadcasting\n",
    "        return sin_pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "088e7473-4237-48fd-89d6-028d972b297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "bb9de396-5c6a-4935-ac6a-313f1b755e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"rope_base\": 500_000.0, \n",
    "    \"rope_freq\": {                        #YaRN\n",
    "        \"factor\": 8.0,\n",
    "        \"low_freq_factor\": 1.0,\n",
    "        \"high_freq_factor\": 4.0,\n",
    "        \"original_context_length\": 8192,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "8fd647d4-870f-4017-9bf6-469658e64ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        mask, cos, sin = SharedBuffers.get_buffers(cfg[\"ctx_length\"], self.head_dim, cfg[\"dtype\"], cfg['rope_base'], cfg['rope_freq'])\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "        self.register_buffer(\"cos\", cos)\n",
    "        self.register_buffer(\"sin\", sin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # k and q are of shape (b, h, n, head_dim)\n",
    "        k = compute_rope(k, self.cos, self.sin)\n",
    "        q = compute_rope(q, self.cos, self.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "5a643ee1-3061-459e-8118-65fb73db5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedBuffers:\n",
    "    _buffers = {} # In case we run with different configs\n",
    "\n",
    "    @staticmethod\n",
    "    def get_buffers(context_length, head_dim, dtype=torch.float32, rope_base = 10_000, freq_config = None):\n",
    "        key = (context_length, head_dim, dtype, rope_base, tuple(freq_config.values()) if freq_config else freq_config)\n",
    "\n",
    "        if key not in SharedBuffers._buffers:\n",
    "            mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "            cos, sin = precompute_rope_params(head_dim, rope_base, context_length, freq_config)\n",
    "            if dtype is not None:\n",
    "                cos = cos.to(dtype)\n",
    "                sin = sin.to(dtype)\n",
    "            SharedBuffers._buffers[key] = (mask, cos, sin)\n",
    "\n",
    "        return SharedBuffers._buffers[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "79699db8-bc96-498e-9998-ead18facb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_rope_params(head_dim, theta_base=10_000, context_length=4096, freq_config=None):\n",
    "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "    #thetas\n",
    "    freqs = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2).float() / head_dim))\n",
    "    # Rescale\n",
    "    if freq_config is not None:\n",
    "        # YaRN works by preserving (not-scaling) high frequencies, and scaling low frequencies down (increasing long wavelengths)\n",
    "        low_freq_wavelen = freq_config[\"original_context_length\"] / freq_config[\"low_freq_factor\"]\n",
    "        high_freq_wavelen = freq_config[\"original_context_length\"] / freq_config[\"high_freq_factor\"]\n",
    "        wavelens = 2 * torch.pi / freqs\n",
    "        # When wavelengths > context_length, decrease frequency\n",
    "        freqs_llama = torch.where(\n",
    "            wavelens > low_freq_wavelen, freqs / freq_config[\"factor\"], freqs\n",
    "        )\n",
    "        \n",
    "        smooth_factor = (freq_config[\"original_context_length\"] / wavelens - freq_config[\"low_freq_factor\"]) / (\n",
    "            freq_config[\"high_freq_factor\"] - freq_config[\"low_freq_factor\"]\n",
    "        )\n",
    "        smoothed_freqs = (\n",
    "            (1 - smooth_factor) * (freqs / freq_config[\"factor\"]) + smooth_factor * freqs\n",
    "        )\n",
    "        is_medium_freq = (wavelens >= high_freq_wavelen) & (wavelens <= low_freq_wavelen)\n",
    "        # When 1/4*context_length < wavelengths < context_length, decrease frequency by a smoothed amount\n",
    "        freqs_llama = torch.where(is_medium_freq, smoothed_freqs, freqs_llama)\n",
    "        freqs = freqs_llama\n",
    "    ms = torch.arange(context_length)\n",
    "    # Shape: (context_length, head_dim // 2)\n",
    "    angles = ms[:, None] * freqs[None, :]  \n",
    "    # Expand angles to match the head_dim, Shape: (context_length, head_dim)\n",
    "    angles = torch.cat([angles, angles], dim=1)\n",
    "    cos = torch.cos(angles)\n",
    "    sin = torch.sin(angles)\n",
    "    return cos, sin # matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "fd58ddf6-db3a-4681-a3ff-17c14858b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rope(x, cos, sin):\n",
    "    # See notes to understand why this works\n",
    "    # x: (batch_size, num_heads, num_tokens, head_dim)\n",
    "    batch_size, num_heads, num_tokens, head_dim = x.shape\n",
    "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
    "\n",
    "    # Adjust sin and cos shapes\n",
    "    cos = cos[:num_tokens, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, num_tokens, head_dim)\n",
    "    sin = sin[:num_tokens, :].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Reorder matrix columns\n",
    "    x1 = x[..., : head_dim // 2]  # First half\n",
    "    x2 = x[..., head_dim // 2 :]  # Second half\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    x_rotated = (x * cos) + (rotated * sin)\n",
    "\n",
    "    return x_rotated.to(dtype=x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc15b5f-16b5-47ed-a261-c4efc1566ed6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f7f2fd6-7224-4c92-8675-dfc3e359fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels = 3,\n",
    "        output_channels = 3,\n",
    "        base_channels = 64,\n",
    "        channel_multipliers = [1,2,4]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        levels = len(channel_multipliers)\n",
    "        channels_list = [m*base_channels for m in channel_multipliers]\n",
    "        input_layers = []\n",
    "        output_layers = []\n",
    "        for i in range(len(channels_list)):\n",
    "            input_channel_num = input_channels if i == 0 else channels_list[i-1]\n",
    "            input_layers.append(nn.Conv2d(input_channel_num, channels_list[i], kernel = 3, padding = 1))\n",
    "            # Downsample\n",
    "            input_layers.append(nn.Conv2d(channels_list[i], channels_list[i], kernel = 3, padding = 1, stride = 2))\n",
    "        for i in reverse(range(len(channels_list))):\n",
    "            output_channel_num = output_channels if i == 0 else channels_list[i-1]\n",
    "            output_layers.append(nn.Conv2d(channels_list[i]*2, output_channel_num, kernel = 3, padding = 1))\n",
    "        self.input_blocks = nn.Sequential(*input_layers)\n",
    "        self.middle_blocks = nn.Conv2d(channels_list[-1], channels_list[-1], kernel = 1, padding = 1)\n",
    "        self.output_blocks = nn.Sequential(*output_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_blocks = []\n",
    "        for block in self.input_blocks:\n",
    "            x = block(x)\n",
    "            input_blocks.append(x)\n",
    "        x = self.middle_blocks(x)\n",
    "        for block in self.output_blocks:\n",
    "            x = F.interpolate(x, scale_factor = 2)\n",
    "            x = torch.cat([x, input_blocks.pop()], dim = 1)\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099a892-155f-4ea1-a514-7703aa25596d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84248ce-f939-4d8a-95c3-2eca00fe6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOE(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_experts: int,\n",
    "            top_k: int,\n",
    "            embed_dim: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        self.experts = [nn.Linear(embed_dim, embed_dim, bias=False) for _ in range(num_experts)]\n",
    "        self.router = nn.Linear(embed_dim, num_experts)\n",
    "        # self.noisy_router = nn.Linear(embed_dim, num_experts)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, seq_len, embed_dim = x.shape\n",
    "        num_tokens = b * seq_len\n",
    "        # (b x seq_len x num_experts)\n",
    "        logits = self.router(x)\n",
    "        # noise_logits = self.noisy_router(x)\n",
    "        # noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
    "        # logits += noise_logits\n",
    "        # (b x seq_len x top_k), (b x seq_len x top_k)\n",
    "        top_k_logits, indices = torch.topk(logits, self.top_k, dim=-1)\n",
    "        neg_infty = torch.full_like(logits, -torch.inf)\n",
    "        # (b x seq_len x num_experts)\n",
    "        logits = neg_infty.scatter(-1, indices, top_k_logits)\n",
    "        # recall num_tokens = b x seq_len\n",
    "        probs = F.softmax(logits, dim=-1).reshape(num_tokens, self.num_experts)\n",
    "        x = x.reshape(num_tokens, embed_dim)\n",
    "        output = torch.zeros((num_tokens, embed_dim))\n",
    "        for i in range(len(self.experts)):\n",
    "            expert = self.experts[i]\n",
    "            # length num_tokens\n",
    "            routed_to_i_mask = (indices == i).any(dim=-1).flatten()\n",
    "            if routed_to_i_mask.any():\n",
    "                filter_x = x[routed_to_i_mask]\n",
    "                filter_x = expert(filter_x)\n",
    "                filter_probs = probs[routed_to_i_mask, i][:, None]\n",
    "                filter_x *= filter_probs\n",
    "                output[routed_to_i_mask] += filter_x\n",
    "        return output.reshape(b, seq_len, embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2beb357-a626-44c6-aa53-00524df0340d",
   "metadata": {},
   "source": [
    "# PPO Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d494dfe-a467-4d45-9273-d06eba345b90",
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<string>, line 146)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<string>:146\u001b[0;36m\u001b[0m\n\u001b[0;31m    if self.seed is not None:\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "class PPO:\n",
    "\tdef __init__(self, policy_class, env, **hyperparameters):\n",
    "\t\t# Make sure the environment is compatible with our code\n",
    "\t\tassert(type(env.observation_space) == gym.spaces.Box)\n",
    "\t\tassert(type(env.action_space) == gym.spaces.Box)\n",
    "\n",
    "\t\t# Initialize hyperparameters for training with PPO\n",
    "\t\tself._init_hyperparameters(hyperparameters)\n",
    "\n",
    "\t\t# Extract environment information\n",
    "\t\tself.env = env\n",
    "\t\tself.obs_dim = env.observation_space.shape[0]\n",
    "\t\tself.act_dim = env.action_space.shape[0]\n",
    "\n",
    "\t\t # Initialize actor and critic networks\n",
    "\t\tself.actor = policy_class(self.obs_dim, self.act_dim)  # ALG STEP 1, can do FFN for now\n",
    "\t\tself.critic = policy_class(self.obs_dim, 1)\n",
    "\n",
    "\t\t# Initialize optimizers for actor and critic\n",
    "\t\tself.actor_optim = Adam(self.actor.parameters(), lr=self.lr)\n",
    "\t\tself.critic_optim = Adam(self.critic.parameters(), lr=self.lr)\n",
    "\n",
    "\t\t# Initialize the covariance matrix used to query the actor for actions\n",
    "\t\tself.cov_var = torch.full(size=(self.act_dim,), fill_value=0.5)\n",
    "\t\tself.cov_mat = torch.diag(self.cov_var)\n",
    "\n",
    "\tdef learn(self, total_timesteps):\n",
    "\t\tt_so_far = 0 # Timesteps simulated so far\n",
    "\t\ti_so_far = 0 # Iterations ran so far\n",
    "\t\twhile t_so_far < total_timesteps:                                                                       # ALG STEP 2\n",
    "            # frac = (t_so_far - 1.0) / total_timesteps\n",
    "            # new_lr = self.lr * (1.0 - frac)\n",
    "            # new_lr = max(new_lr, 0.0)\n",
    "            # self.actor_optim.param_groups[0][\"lr\"] = new_lr\n",
    "            # self.critic_optim.param_groups[0][\"lr\"] = new_lr\n",
    "            \n",
    "\t\t\tbatch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens = self.rollout()                     # ALG STEP 3\n",
    "\t\t\tt_so_far += np.sum(batch_lens)\n",
    "\t\t\ti_so_far += 1\n",
    "\n",
    "\t\t\t# Calculate advantage at k-th iteration\n",
    "\t\t\tV, _ = self.evaluate(batch_obs, batch_acts)\n",
    "\t\t\tA_k = batch_rtgs - V.detach()                                                                       # ALG STEP 5\n",
    "\t\t\tA_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10)\n",
    "\n",
    "\t\t\tfor _ in range(self.n_updates_per_iteration):                                                       # ALG STEP 6 & 7\n",
    "                # np.random.shuffle(inds)\n",
    "                # for start in range(0, step, minibatch_size):\n",
    "                #     end = start + minibatch_size\n",
    "                #     idx = inds[start:end]\n",
    "                #     mini_obs = batch_obs[idx]\n",
    "                #     mini_acts = batch_acts[idx]\n",
    "                #     mini_log_prob = batch_log_probs[idx]\n",
    "                #     mini_advantage = A_k[idx]\n",
    "                #     mini_rtgs = batch_rtgs[idx]\n",
    "\t\t\t\tV, curr_log_probs, entropy = self.evaluate(batch_obs, batch_acts)\n",
    "\t\t\t\tratios = torch.exp(curr_log_probs - batch_log_probs)\n",
    "                # approx_kl = ((ratios - 1) - logratios).mean()\n",
    "                # if approx_kl > self.target_kl:\n",
    "                #     break\n",
    "\t\t\t\tsurr1 = ratios * A_k\n",
    "\t\t\t\tsurr2 = torch.clamp(ratios, 1 - self.clip, 1 + self.clip) * A_k\n",
    "\t\t\t\tactor_loss = (-torch.min(surr1, surr2)).mean() # neg because we want to maximize\n",
    "                # actor_loss -= self.ent_coef * entropy.mean()\n",
    "\t\t\t\tcritic_loss = nn.MSELoss()(V, batch_rtgs)\n",
    "\n",
    "\t\t\t\tself.actor_optim.zero_grad()\n",
    "\t\t\t\tactor_loss.backward(retain_graph=True)\n",
    "                nn.utils.clip_grad_norm_(self.actor.parameters(), self.max_grad_norm)\n",
    "\t\t\t\tself.actor_optim.step()\n",
    "\n",
    "\t\t\t\tself.critic_optim.zero_grad()\n",
    "\t\t\t\tcritic_loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.critic.parameters(), self.max_grad_norm)\n",
    "\t\t\t\tself.critic_optim.step()\n",
    "\n",
    "\tdef rollout(self):\n",
    "\t\t\"\"\"\n",
    "\t\t\tReturn:\n",
    "\t\t\t\tbatch_obs - the observations collected this batch. Shape: (number of timesteps, dimension of observation)\n",
    "\t\t\t\tbatch_acts - the actions collected this batch. Shape: (number of timesteps, dimension of action)\n",
    "\t\t\t\tbatch_log_probs - the log probabilities of each action taken this batch. Shape: (number of timesteps)\n",
    "\t\t\t\tbatch_rtgs - the Rewards-To-Go of each timestep in this batch. Shape: (number of timesteps)\n",
    "\t\t\t\tbatch_lens - the lengths of each episode this batch. Shape: (number of episodes)\n",
    "\t\t\"\"\"\n",
    "\t\t# Batch data. For more details, check function header.\n",
    "\t\tbatch_obs = []\n",
    "\t\tbatch_acts = []\n",
    "\t\tbatch_log_probs = []\n",
    "\t\tbatch_rews = []\n",
    "\t\tbatch_rtgs = []\n",
    "\t\tbatch_lens = []\n",
    "\n",
    "\t\tep_rews = [] # Episodic data. Keeps track of rewards per episode, will get cleared upon each new episode\n",
    "\t\tt = 0 # Keeps track of how many timesteps we've run so far this batch\n",
    "\t\twhile t < self.timesteps_per_batch:\n",
    "\t\t\tep_rews = [] # rewards collected per episode\n",
    "\t\t\t# Reset the environment. \n",
    "\t\t\tobs, _ = self.env.reset()\n",
    "\t\t\tdone = False\n",
    "\n",
    "\t\t\t# Run an episode for a maximum of max_timesteps_per_episode timesteps\n",
    "\t\t\tfor ep_t in range(self.max_timesteps_per_episode):\n",
    "\t\t\t\tt += 1 \n",
    "\t\t\t\tbatch_obs.append(obs)\n",
    "\t\t\t\taction, log_prob = self.get_action(obs)\n",
    "\t\t\t\tobs, rew, terminated, truncated, _ = self.env.step(action)\n",
    "\t\t\t\tdone = terminated | truncated\n",
    "\n",
    "\t\t\t\tep_rews.append(rew)\n",
    "\t\t\t\tbatch_acts.append(action)\n",
    "\t\t\t\tbatch_log_probs.append(log_prob)\n",
    "\n",
    "\t\t\t\tif done:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tbatch_lens.append(ep_t + 1)\n",
    "\t\t\tbatch_rews.append(ep_rews)\n",
    "\n",
    "\t\tbatch_obs = torch.tensor(batch_obs, dtype=torch.float)\n",
    "\t\tbatch_acts = torch.tensor(batch_acts, dtype=torch.float)\n",
    "\t\tbatch_log_probs = torch.tensor(batch_log_probs, dtype=torch.float)\n",
    "\t\tbatch_rtgs = self.compute_rtgs(batch_rews)                                                              # ALG STEP 4\n",
    "\n",
    "\t\treturn batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens\n",
    "\n",
    "\tdef compute_rtgs(self, batch_rews):\n",
    "\t\t\"\"\"\n",
    "\t\t\tInput:\n",
    "\t\t\t\tbatch_rews - the rewards in a batch, Shape: (number of episodes, number of timesteps per episode)\n",
    "\t\t\tReturn:\n",
    "\t\t\t\tbatch_rtgs - the rewards to go, Shape: (number of timesteps in batch)\n",
    "\t\t\"\"\"\n",
    "\t\tbatch_rtgs = []\n",
    "\t\tfor ep_rews in reversed(batch_rews):\n",
    "\t\t\tdiscounted_reward = 0\n",
    "\t\t\tfor rew in reversed(ep_rews):\n",
    "\t\t\t\tdiscounted_reward = rew + discounted_reward * self.gamma\n",
    "\t\t\t\tbatch_rtgs.insert(0, discounted_reward)\n",
    "\t\tbatch_rtgs = torch.tensor(batch_rtgs, dtype=torch.float)\n",
    "\t\treturn batch_rtgs\n",
    "\n",
    "\tdef get_action(self, obs):\n",
    "\t\tmean = self.actor(obs)\n",
    "\t\tdist = MultivariateNormal(mean, self.cov_mat)\n",
    "\t\taction = dist.sample()\n",
    "\t\tlog_prob = dist.log_prob(action)\n",
    "\t\treturn action.detach().numpy(), log_prob.detach()\n",
    "\n",
    "\tdef evaluate(self, batch_obs, batch_acts):\n",
    "\t\tV = self.critic(batch_obs).squeeze()\n",
    "\t\tmean = self.actor(batch_obs)\n",
    "\t\tdist = MultivariateNormal(mean, self.cov_mat)\n",
    "\t\tlog_probs = dist.log_prob(batch_acts)\n",
    "\t\treturn V, log_probs, dist.entropy()\n",
    "\n",
    "\tdef _init_hyperparameters(self, hyperparameters):\n",
    "\t\tself.timesteps_per_batch = 4800                 # Number of timesteps to run per batch\n",
    "\t\tself.max_timesteps_per_episode = 1600           # Max number of timesteps per episode\n",
    "\t\tself.n_updates_per_iteration = 5                # Number of times to update actor/critic per iteration\n",
    "\t\tself.lr = 0.005                                 # Learning rate of actor optimizer\n",
    "\t\tself.gamma = 0.95                               # Discount factor to be applied when calculating Rewards-To-Go\n",
    "\t\tself.clip = 0.2                                 # Recommended 0.2, helps define the threshold to clip the ratio during SGA\n",
    "        if self.seed is not None:\n",
    "            torch.manual_seed(self.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30123f53-511f-4853-b48d-61c72b3d4f93",
   "metadata": {},
   "source": [
    "## GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09eb1ef-380f-46c7-b586-2644ab64e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gae(self, rewards, values, dones):\n",
    "    batch_advantages = []\n",
    "    for ep_rews, ep_vals, ep_dones in zip(rewards, values, dones):\n",
    "        advantages = []\n",
    "        last_advantage = 0\n",
    "\n",
    "        for t in reversed(range(len(ep_rews))):\n",
    "            if t + 1 < len(ep_rews):\n",
    "                delta = ep_rews[t] + self.gamma * ep_vals[t+1] * (1 - ep_dones[t+1]) - ep_vals[t]\n",
    "            else:\n",
    "                delta = ep_rews[t] - ep_vals[t]\n",
    "\n",
    "            advantage = delta + self.gamma * self.lam * (1 - ep_dones[t]) * last_advantage\n",
    "            last_advantage = advantage\n",
    "            advantages.insert(0, advantage)\n",
    "\n",
    "        batch_advantages.extend(advantages)\n",
    "\n",
    "    return torch.tensor(batch_advantages, dtype=torch.float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
