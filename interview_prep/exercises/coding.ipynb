{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776b273c-4c3d-42b3-a844-9df49d9a57ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "863059eb-d61a-4260-9e42-9652502f44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ccfbb2e-1f75-429c-af8d-992aced36625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "# Continuous\n",
    "np.random.seed(42)  \n",
    "m = 100  \n",
    "X = 2 * np.random.rand(m, 1)  \n",
    "y = 4 + 3 * X + np.random.randn(m, 1)  \n",
    "X_b = add_dummy_feature(X)  \n",
    "X_new = np.array([[0], [2]])\n",
    "\n",
    "# Categorical\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y_bin = (iris.target == 2) \n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028abaa-138d-4aad-97b0-f3c46bfeab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern is\n",
    "# model()\n",
    "# model.fit(X_train, y_train)\n",
    "# model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44cc38cb-f6fc-49f0-90ad-5f0e6d04e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "pred_lin = lin_reg.predict(X_new)\n",
    "\n",
    "ridge_reg = Ridge(alpha=100, solver=\"cholesky\")\n",
    "ridge_reg.fit(X, y)\n",
    "pred_ridge = ridge_reg.predict(X_new)\n",
    "\n",
    "lasso_reg = Lasso(alpha=100/(2*len(X)))\n",
    "lasso_reg.fit(X, y)\n",
    "pred_lasso = lasso_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "169c62f3-8d3f-436d-b500-302603893717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 47,  3],\n",
       "       [ 0,  2, 48]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X, y) # allows for multi-class\n",
    "y_pred = log_reg.predict(X)\n",
    "cm = confusion_matrix(y, y_pred) \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "131aaf76-6270-4e7d-91aa-185182b8faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "svm_clf1 = LinearSVC(C=1, max_iter=10_000, dual=True, random_state=42) # linear kernel, can use SVC for rbf kernel\n",
    "# model_loss = C*classification_loss + penalty, so lower C means higher regularization\n",
    "scaled_svm_clf1 = make_pipeline(scaler, svm_clf1)\n",
    "scaled_svm_clf1.fit(X, y) # allows for multi-class\n",
    "scaled_svm_clf1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6466ee8b-d74c-42b7-8d06-8a0c35fdfeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X, y)\n",
    "tree_clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523b33a-43ea-4a07-a827-633c4f23709b",
   "metadata": {},
   "source": [
    "# NN Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772bef86-c24c-428e-8428-7b18d8496bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088351f9-b45e-4ca5-ac95-43a11eaf1f58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2ddebfeb-dd5e-4c0b-9ec0-c6b3b4383493",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, size, std=0.1):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3641ac6-7fb9-4be2-8268-ad146197459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, act_fn = nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = act_fn\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    # One layer and no activation for glm\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6dd6fb-a888-4ec3-b36c-64f894922f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.reshape(-1,)\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61763efd-c9d2-4c61-889b-e8596ca1d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() \n",
    "    true_preds, num_preds = 0., 0.\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            pred_labels = (torch.sigmoid(preds) > 0.5).int().reshape(-1)\n",
    "            true_preds += (pred_labels == data_labels).sum().float()\n",
    "            num_preds += data_labels.shape[0]\n",
    "\n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd121db-7c90-47ed-a706-eb083554e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\") if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2780019e-c1f4-44b0-8f5d-219d4aa1ccee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce31e0ea7a2f49e4a23caa74cff7eaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'linear1.weight': tensor([[-0.6186, -1.2413],\n",
      "        [ 2.4791,  2.3084],\n",
      "        [-1.9578,  2.8000],\n",
      "        [ 3.2432, -2.6608]], device='mps:0'), 'linear1.bias': tensor([ 1.3746, -0.7270,  0.7655,  1.2364], device='mps:0'), 'linear2.weight': tensor([[ 2.0459,  3.4998, -3.6495, -4.2671]], device='mps:0'), 'linear2.bias': tensor([0.8146], device='mps:0')})\n",
      "Accuracy of the model: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor_str.py:145: UserWarning: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729646995093/work/aten/src/ATen/native/mps/operations/Indexing.mm:361.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "set_seed(1)\n",
    "# Change this to MSE for linear regression\n",
    "# Change this to CrossEntropyLoss for multi-category, but rmb to change num_outputs to number of classes\n",
    "loss_module = nn.BCEWithLogitsLoss()\n",
    "train_dataset = XORDataset(size=2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataset = XORDataset(size=500)\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False)\n",
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "train_model(model, optimizer, train_data_loader, loss_module)\n",
    "\n",
    "# Save model\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)\n",
    "# torch.save(state_dict, \"our_model.tar\")\n",
    "# state_dict = torch.load(\"our_model.tar\")\n",
    "# new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "# new_model.load_state_dict(state_dict)\n",
    "\n",
    "eval_model(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65cd243-9670-4841-807c-7b2816aadb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "# define dataloaders\n",
    "# define model\n",
    "# define device and set seed\n",
    "# define optimizer\n",
    "# define loss module\n",
    "# model.to(device)\n",
    "# model.train()\n",
    "# for each epoch\n",
    "# for data_input, data_label in data_loader:\n",
    "# predict\n",
    "# loss\n",
    "# zero\n",
    "# loss.backward\n",
    "# optimizer.step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f536113-1d68-4c73-ac0e-50184edb9f86",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f72aa218-1f56-4fe2-8537-2c88531a0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORDataset(data.Dataset):\n",
    "    def __init__(self, size, std = 0.1):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.data = torch.randint(2, size = (size, 2), dtype = torch.float32)\n",
    "        self.targets = (self.data.sum(axis = 1) == 1).to(torch.float32)\n",
    "        self.data += torch.randn(self.data.shape)*std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd698384-807e-4bef-8967-a071d630695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_inputs, num_hidden, num_classes, act_fn = nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = act_fn\n",
    "        self.linear2 = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c26bb5b-f893-4ed6-9598-964d2cd28ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d128cdaf-5408-43cf-ab34-f76cedbedc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleClassifier(\n",
       "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (act_fn): Tanh()\n",
       "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "set_seed(42)\n",
    "train_dataset = XORDataset(2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "model = SimpleClassifier(2, 4, 1)\n",
    "device = torch.device(\"mps\") if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5113f71b-45d9-4086-b480-75aa8f3d9718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "50.32\n",
      "48.6\n",
      "47.96\n",
      "46.28\n",
      "48.96\n",
      "47.64\n",
      "49.64\n",
      "49.96\n",
      "50.08\n",
      "49.36\n",
      "51.8\n",
      "50.72\n",
      "51.64\n",
      "51.96\n",
      "52.12\n",
      "51.36\n",
      "56.36\n",
      "51.52\n",
      "50.8\n",
      "52.16\n",
      "50.92\n",
      "51.32\n",
      "51.2\n",
      "50.76\n",
      "51.44\n",
      "50.8\n",
      "52.32\n",
      "55.16\n",
      "62.76\n",
      "78.48\n",
      "89.4\n",
      "97.4\n",
      "99.4\n",
      "99.8\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "set_seed(42)\n",
    "train_dataset = XORDataset(2500)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "model = SimpleClassifier(2, 4, 1)\n",
    "device = torch.device(\"mps\") if torch.mps.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    sum_correct = 0\n",
    "    sum_data_points = 0\n",
    "    for data_input, data_label in train_data_loader:\n",
    "        data_input = data_input.to(device)\n",
    "        data_label = data_label.to(device)\n",
    "        pred = model(data_input).flatten()\n",
    "        loss = loss_fn(pred, data_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_data_points += len(data_input)\n",
    "        sum_correct += ((pred > 0) == data_label).sum()\n",
    "    print(np.round((100*sum_correct/sum_data_points).cpu().item(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6d1a8-df5f-41d7-85a2-960ca26d602f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "81efbabf-2fca-47e4-92a9-15c1c2698ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = self.__class__.__name__\n",
    "\n",
    "class Identity(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x * (x > 0)\n",
    "\n",
    "class Tanh(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return (torch.exp(x) - torch.exp(-x))/(torch.exp(x) + torch.exp(-x))\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return 1/(1 + torch.exp(-x))\n",
    "\n",
    "class SoftPlus(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return torch.log(1 + np.exp(x))\n",
    "\n",
    "class ELU(ActivationFunction):\n",
    "    def __init__(self, alpha = 1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.where(x >= 0, x, self.alpha*(torch.exp(x)-1))\n",
    "\n",
    "class GeLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1 + torch.tanh(torch.tensor(2/torch.pi)*(x + 0.044715*x**3)))\n",
    "\n",
    "class SiLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x/(1 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec2d8d-f51e-4daa-af15-bcf2f2d472f0",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23431610-2c62-401e-bf47-2eace6d232e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module): \n",
    "    \n",
    "    def __init__(self, act_fn = nn.ReLU(), input_size=784, num_classes=10, hidden_sizes=[512, 256, 256, 128]):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + hidden_sizes\n",
    "        for layer_index in range(1, len(layer_sizes)):\n",
    "            layers += [nn.Linear(layer_sizes[layer_index-1], layer_sizes[layer_index]),\n",
    "                       act_fn]\n",
    "        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n",
    "        self.layers = nn.Sequential(*layers) \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.endswith(\"bias\"):\n",
    "                nn.init.zeros_(param)\n",
    "            else:\n",
    "                # nn.init.normal_(param, std = np.sqrt(2/(param.shape[0] + param.shape[1]))) # xavier\n",
    "                nn.init.normal_(param, std = np.sqrt(2/param.shape[1])) # kaiming\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e7b50-b574-4f27-be99-fa7550c395d4",
   "metadata": {},
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "06ec50eb-24f4-4bbf-914a-1839d65adaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerTemplate:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()\n",
    "                p.grad.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                self.update_param(p)\n",
    "            \n",
    "    def update_param(self, p):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "13185628-f7a9-450f-a116-b0e62197ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(OptimizerTemplate):\n",
    "    def update_param(self, p):\n",
    "        p_update = -self.lr*p.grad\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "333351ab-3e51-41cb-8d8f-bc04b56c96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, momentum = 0.0):\n",
    "        super().__init__()\n",
    "        self.beta1 = momentum\n",
    "        self.param_momentum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "    \n",
    "    def update_param(self, p):\n",
    "        self.param_momentum[p] = p.grad + self.beta1*self.param_momentum[p]\n",
    "        p_update = -self.lr * self.param_momentum[p]\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ab29fc5e-7a46-43f7-ba06-01198340398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, epsilon = 1e-8):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_sq_grad_sum[p].add_(p.grad**2)\n",
    "        p_update = -self.lr * p.grad / torch.sqrt(self.param_sq_grad_sum[p] + self.epsilon)\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4079e675-fcc5-4c75-bb80-ca6bdc33f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSProp(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, epsilon = 1e-8, beta2 = 0.999):\n",
    "        super().__init__()\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_sq_grad_sum[p] = self.beta2*self.param_sq_grad_sum[p] + (1-self.beta2)*(p.grad**2)\n",
    "        p_update = -self.lr * p.grad / torch.sqrt(self.param_sq_grad_sum[p] + self.epsilon)\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d08ddac0-8b9d-48ef-81ff-d8b560ba71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaDelta(OptimizerTemplate):\n",
    "    def __init__(self, params, lr = 1.0, epsilon = 1e-8, beta2 = 0.999): \n",
    "        super().__init__()\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.param_delta = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_sq_grad_sum[p] = self.beta2*self.param_sq_grad_sum[p] + (1-self.beta2)*(p.grad**2)\n",
    "        ada_lr = torch.sqrt(self.param_delta[p] + self.epsilon)\n",
    "        p_update = -self.lr * ada_lr * p.grad / torch.sqrt(self.param_sq_grad_sum[p] + self.epsilon)\n",
    "        p.add_(p_update)\n",
    "        self.param_delta[p] = self.beta2*self.param_delta[p] + (1-self.beta2)*((p_update/self.lr)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7f342c1e-b603-4734-a932-cfa6e5611c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(OptimizerTemplate):\n",
    "    def __init__(self, params, lr, epsilon = 1e-8, beta1 = 0.99, beta2 = 0.999):\n",
    "        super().__init__()\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.param_step = {p : 0 for p in self.params}\n",
    "        self.param_momentum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "        self.param_sq_grad_sum = {p : torch.zeros_like(p.data) for p in self.params}\n",
    "\n",
    "    def update_param(self, p):\n",
    "        self.param_step[p] += 1\n",
    "        self.param_momentum[p] = self.beta1*self.param_momentum[p] + (1-self.beta1)*p.grad\n",
    "        self.param_sq_grad_sum[p] = self.beta2*self.param_sq_grad_sum[p] + (1-self.beta2)*(p.grad**2)\n",
    "        beta1_norm = 1 - self.beta1**self.param_step[p]\n",
    "        beta2_norm = 1 - self.beta2**self.param_step[p]\n",
    "        p_update = -self.lr * (self.param_momentum[p]/beta1_norm) / (torch.sqrt(self.param_sq_grad_sum[p]/beta2_norm) + self.epsilon)\n",
    "        p.add_(p_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddceea3-3a33-4e03-97c2-2fdd37ed7195",
   "metadata": {},
   "source": [
    "# Self-Attention / Cross-Attention / Multi-Head Attention / Grouped Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbfff2-058a-4575-ac3f-588349c6cf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf553476-42d2-4166-b2d7-d14e28059301",
   "metadata": {},
   "source": [
    "# GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00552396-b468-47bf-92b8-4bfba7fd676b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597059d5-7a95-4302-b730-f72fe488312f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
